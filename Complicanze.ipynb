{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#CREAZIONE GRAFICO SULLE PRIME 22 DIAGNOSI CON PIU PAZIENTI AFFETTI\n",
    "############################################################################################\n",
    "# Raggruppa per la colonna 'Description' e conta il numero di pazienti in ogni gruppo\n",
    "df = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "grouped = df.groupby('Description').size()\n",
    "\n",
    "# Ordina i dati in ordine decrescente\n",
    "top_22_descriptions = grouped.sort_values(ascending=False).head(22)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "# disegna il barplot\n",
    "sns.barplot(\n",
    "    x=top_22_descriptions.index,\n",
    "    y=top_22_descriptions.values,\n",
    "    hue=top_22_descriptions.index,\n",
    "    palette=\"viridis\",\n",
    "    legend=False,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# prendi le etichette originali, applica wrapping ogni 15 caratteri\n",
    "wrapped = top_22_descriptions.index.to_series().str.wrap(55)\n",
    "\n",
    "# impostale sull'asse x, con rotazione\n",
    "ax.set_xticks(range(len(wrapped)))\n",
    "ax.set_xticklabels(wrapped, rotation=45, ha='right')\n",
    "ax.set_ylabel('Numero di pazienti', fontsize=16)\n",
    "ax.set_xlabel('')  # niente label orizzontale\n",
    "\n",
    "# Etichette numeriche\n",
    "for i, v in enumerate(top_22_descriptions.values):\n",
    "    ax.text(i, v + 1, str(v), ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(top_22_descriptions)\n",
    "############################################################################################"
   ],
   "id": "215fe16e0e5b9310"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#MERGE DELLE TABELLE Diagnostics.csv E Biochemical_parameters.csv E STAMPA DELLE STATISTICHE E\n",
    "#DEI PAZIENTI CHE HANNO UNO SPECIFICA COMPLICAZIONE, IN QUESTO CASO: \"Other and unspecified hyperlipidemia\"\n",
    "############################################################################################\n",
    "diagnostics_df = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "biochemical_df = pd.read_csv(\"Excel/Biochemical_parameters.csv\")\n",
    "# pivot dei parametri\n",
    "bio_wide = biochemical_df.pivot_table(\n",
    "    index=\"Patient_ID\",\n",
    "    columns=\"Name\",\n",
    "    values=\"Value\",\n",
    "    aggfunc=\"mean\"\n",
    ").reset_index()\n",
    "\n",
    "# merge wide\n",
    "merged_wide = pd.merge(\n",
    "    diagnostics_df,\n",
    "    bio_wide,\n",
    "    on=\"Patient_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "#PRINT STATISTICHE\n",
    "# print()\n",
    "# print('numero di righe e colonne')\n",
    "# print(merged_wide.shape)\n",
    "# print()\n",
    "# print('tipi e missing')\n",
    "# print(merged_wide.info())\n",
    "# print()\n",
    "# print('statistiche numeriche di base')\n",
    "# print(merged_wide.describe()) #viene eseguito solo sulle colonne numeriche es:int64\n",
    "# print()\n",
    "\n",
    "\n",
    "# filtri solo le righe con Description == 'Other and unspecified hyperlipidemia'\n",
    "subset = merged_wide[ merged_wide['Description'] == 'Other and unspecified hyperlipidemia' ]\n",
    "\n",
    "\n",
    "#PRINT DI QUANTI VALORI NULLI HA OGNI COLONNA DELLA TABELLA\n",
    "print(\"VALORI NULLI\")\n",
    "nan_mask = subset.isna()\n",
    "nan_count = nan_mask.sum()\n",
    "print(nan_count)\n",
    "\n",
    "\n",
    "\n",
    "#PRINT LISTA PAZIENTI CON QUESTA COMPLICAZIONE (Other and unspecified hyperlipidemia)\n",
    "from IPython.display import display\n",
    "display(subset)\n",
    "\n",
    "############################################################################################"
   ],
   "id": "390f2b8be7f47419"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#GRAFICI DI SESSO E ETA DEI PAZIENTI AFFETTI DA UNA CERTA COMPLICANZA, IN QUESTO CASO LA COMPLICANZA CON CODICE 272.4, OVVERO \"Other and unspecified hyperlipidemia\"\n",
    "############################################################################################\n",
    "diagnostics_df = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "patient_df = pd.read_csv(\"Excel/Patient_info.csv\")\n",
    "\n",
    "#Merge dei dataset su Patient_ID\n",
    "merged = pd.merge(\n",
    "    diagnostics_df,\n",
    "    patient_df,\n",
    "    on=\"Patient_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# STAMPA DEI CODICI CHE HANNO COME DESCRIZIONE DELLA PATOLOGIA \"Other and unspecified hyperlipidemia\"\n",
    "# df_hp = merged[merged[\"Description\"] == \"Other and unspecified hyperlipidemia\"].copy()\n",
    "#\n",
    "# print(df_hp[\"Code\"].tolist())\n",
    "# print(\"Codici unici:\", df_hp[\"Code\"].unique())\n",
    "# print(df_hp[[\"Patient_ID\",\"Code\"]])\n",
    "\n",
    "\n",
    "df_hp = merged[merged[\"Code\"] == \"272.4\"].copy()\n",
    "\n",
    "#calcola l'età (anno corrente 2025)\n",
    "df_hp[\"Età\"] = 2025 - df_hp[\"Birth_year\"]\n",
    "\n",
    "#Grafico distribuzione del sesso\n",
    "\n",
    "light_blue = \"#ADD8E6\"   # “lightblue”\n",
    "light_red  = \"#FFB6C1\"   # “lightpink”\n",
    "\n",
    "# Conta e ordina (per sicurezza) i due valori\n",
    "counts = df_hp[\"Sex\"].value_counts()\n",
    "\n",
    "# Definisci un dizionario di colori\n",
    "color_map = {\"M\": light_blue, \"F\": light_red}\n",
    "colors = [color_map[label] for label in counts.index]\n",
    "\n",
    "# Pie‐chart con colori personalizzati\n",
    "plt.figure(figsize=(6,6))\n",
    "counts.plot.pie(\n",
    "    colors=colors,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    startangle=90,\n",
    "    legend=False\n",
    ")\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"\")\n",
    "plt.axis(\"equal\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Grafico distribuzione dell'età\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.kdeplot(\n",
    "    data=df_hp,\n",
    "    x=\"Età\",\n",
    "    fill=True,        # area sotto la curva colorata\n",
    "    alpha=0.4,        # trasparenza\n",
    "    linewidth=2\n",
    ")\n",
    "plt.title(\"\")\n",
    "plt.xlabel(\"Età\")\n",
    "plt.ylabel(\"Densità stimata\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Istogramma con numero di pazienti per etá\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(\n",
    "    data=df_hp,\n",
    "    x=\"Età\",\n",
    "    bins=10,          # numero di barre (regola a piacere)\n",
    "    stat=\"count\",     # indica di mostrare conteggi anziché densità\n",
    "    discrete=False    # False di default: barre continue\n",
    ")\n",
    "plt.xlabel(\"Età\")\n",
    "plt.ylabel(\"Numero di pazienti\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "############################################################################################"
   ],
   "id": "8ce23be66620a506"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "#GRAFICO CHE MOSTRA LA DISTRIBUZIONE DI COMPLICANZE, SESSO ED ETA SU TUTTI I PAZIENTI\n",
    "############################################################################################\n",
    "# 1) Caricamento\n",
    "diagnostics_df = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "patient_df     = pd.read_csv(\"Excel/Patient_info.csv\")\n",
    "\n",
    "# 2) Costruisci il flag \"has complication\" ONE‑ROW‑PER‑PATIENT\n",
    "diagnostics_df[\"Has_complication\"] = diagnostics_df[\"Description\"].notna()\n",
    "complication_flag = (\n",
    "    diagnostics_df\n",
    "    .groupby(\"Patient_ID\")[\"Has_complication\"]\n",
    "    .any()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 3) Merge: UNA riga per paziente\n",
    "merged = pd.merge(\n",
    "    patient_df,\n",
    "    complication_flag,\n",
    "    on=\"Patient_ID\",\n",
    "    how=\"left\"\n",
    ")\n",
    "# i pazienti senza diagnosi avranno NaN → False\n",
    "merged[\"Has_complication\"] = (\n",
    "    merged[\"Has_complication\"]\n",
    "      .astype(\"boolean\")      # diventa BooleanDtype (nullable)\n",
    "      .fillna(False)          # i NaN diventano False, senza warning\n",
    ")\n",
    "merged[\"Complicanza\"] = merged[\"Has_complication\"].map({True:\"Sì\", False:\"No\"})\n",
    "\n",
    "# verifica\n",
    "assert len(merged) == 736, f\"Righe in merged = {len(merged)} (attesi 736)\"\n",
    "\n",
    "# 4) Calcola età e fasce\n",
    "merged[\"Eta\"] = 2025 - merged[\"Birth_year\"]\n",
    "bins   = [0,20,30,40,50,60,70,80,90,120]\n",
    "labels = ['0-20','21-30','31-40','41-50','51-60','61-70','71-80','81-90','91+']\n",
    "merged[\"Eta_bin\"] = pd.cut(merged[\"Eta\"], bins=bins, labels=labels, right=True)\n",
    "\n",
    "# 5) Tabella di contingenza\n",
    "table = (\n",
    "    merged\n",
    "    .groupby([\"Eta_bin\",\"Sex\",\"Complicanza\"], observed=True)\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "\n",
    "# 6) Estrai M e F e reindicizza tutte le fasce\n",
    "table_M = table.xs(\"M\", level=\"Sex\").reindex(labels, fill_value=0)\n",
    "table_F = table.xs(\"F\", level=\"Sex\").reindex(labels, fill_value=0)\n",
    "\n",
    "# 7) Prepara i vettori per il plot\n",
    "x      = np.arange(len(labels))\n",
    "width  = 0.35\n",
    "no_M   = table_M[\"No\"];   yes_M = table_M[\"Sì\"]\n",
    "no_F   = table_F[\"No\"];   yes_F = table_F[\"Sì\"]\n",
    "\n",
    "colors = {\n",
    "    'M_no':  '#ADD8E6',  # lightblue\n",
    "    'M_yes': '#4682B4',  # steelblue\n",
    "    'F_no':  '#FFB6C1',  # lightpink\n",
    "    'F_yes': '#FF69B4',  # hotpink\n",
    "}\n",
    "\n",
    "# 8) Disegna il bar‑chart impilato\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "bars_M_no  = ax.bar(x - width/2, no_M,  width, label='Maschi senza complicanze', color=colors['M_no'])\n",
    "bars_M_yes = ax.bar(x - width/2, yes_M, width, bottom=no_M, label='Maschi con complicanze',    color=colors['M_yes'])\n",
    "bars_F_no  = ax.bar(x + width/2, no_F,  width, label='Femmine senza complicanze', color=colors['F_no'])\n",
    "bars_F_yes = ax.bar(x + width/2, yes_F, width, bottom=no_F, label='Femmine con complicanze',    color=colors['F_yes'])\n",
    "\n",
    "# 9) Annotazioni dei valori dentro le barre\n",
    "def annotate_bars(bars):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h>0:\n",
    "            ax.annotate(f'{int(h)}',\n",
    "                        xy=(bar.get_x()+bar.get_width()/2, bar.get_y()+h/2),\n",
    "                        ha='center', va='center', fontsize=8)\n",
    "\n",
    "for grp in (bars_M_no, bars_M_yes, bars_F_no, bars_F_yes):\n",
    "    annotate_bars(grp)\n",
    "\n",
    "# 10) Etichette e stile\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45)\n",
    "ax.set_xlabel(\"Fascia d'età\")\n",
    "ax.set_ylabel(\"Numero pazienti\")\n",
    "ax.legend(title=\"Legenda\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "############################################################################################"
   ],
   "id": "4b1996f9e47d3380"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ANALISI TIR\n",
    "############################################################################################\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 1) CARICAMENTO DEI DATI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "df = pd.read_csv(\"Excel/Glucose_measurements.csv\")\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "parte1 = pd.read_csv(\"Excel/Parte1.csv\")\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 2) FUNZIONE PER CALCOLARE IL TIR DI UN PAZIENTE\n",
    "#    Prende in ingresso il DataFrame delle misurazioni di un singolo paziente\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "def calculate_tir(misurazioni):\n",
    "    totale = len(misurazioni)  # numero totale di misurazioni\n",
    "    righe_valide = misurazioni[\n",
    "        (misurazioni['Measurement'] >= 70) &\n",
    "        (misurazioni['Measurement'] <= 180)\n",
    "    ]  # seleziona le misurazioni in range 70-180 mg/dL\n",
    "    tir = len(righe_valide) / totale * 100  # percentuale Time In Range\n",
    "    return tir\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 3) CALCOLO TIR COMPLESSIVO PER OGNI PAZIENTE\n",
    "#    Uso include_groups=False per evitare il DeprecationWarning\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "pazienti = df.groupby('Patient_ID')\n",
    "tir_by_paziente = pazienti.apply(\n",
    "    calculate_tir,\n",
    "    include_groups=False              # evita warning su grouping columns\n",
    ").reset_index(name='%TIR')\n",
    "\n",
    "\n",
    "# Stampa del DataFrame %TIR\n",
    "print(tir_by_paziente)\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 4) GRAFICO BAR PLOT PER %TIR DI OGNI PAZIENTE\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(tir_by_paziente['Patient_ID'], tir_by_paziente['%TIR'], color='skyblue')\n",
    "plt.xticks([])  # nasconde le etichette X per chiarezza\n",
    "plt.ylabel('% Time In Range (70–180 mg/dL)')\n",
    "plt.xlabel('Pazienti')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche descrittive di %TIR\n",
    "print(tir_by_paziente['%TIR'].describe())\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 5) RAGGRUPPAMENTO IN INTERVALLI E CONTEGGIO PAZIENTI\n",
    "#    Uso observed=False per evitare il FutureWarning\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "bins = [0, 1] + list(range(10, 110, 10))\n",
    "tir_by_paziente['Interval'] = pd.cut(\n",
    "    tir_by_paziente['%TIR'],\n",
    "    bins=bins,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# Flag per presenza di diagnosi\n",
    "pazienti_con_diagnosi = set(diagnostics['Patient_ID'])\n",
    "tir_by_paziente['Has_Diagnosis'] = tir_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# Conteggio per ciascun intervallo e condizione\n",
    "conta_per_interval = (\n",
    "    tir_by_paziente\n",
    "      .groupby(\n",
    "          ['Interval', 'Has_Diagnosis'],\n",
    "          observed=False              # evita warning su observed default\n",
    "      )\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 6) ISTOGRAMMA A BARRE AFFIANCATE PER INTERVALLO\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index = list(range(len(conta_per_interval)))\n",
    "\n",
    "bar1 = plt.bar(\n",
    "    [i - bar_width/2 for i in index],\n",
    "    conta_per_interval[False],\n",
    "    width=bar_width,\n",
    "    label='Senza Complicanze',\n",
    "    color='skyblue',\n",
    "    edgecolor='black'\n",
    ")\n",
    "bar2 = plt.bar(\n",
    "    [i + bar_width/2 for i in index],\n",
    "    conta_per_interval[True],\n",
    "    width=bar_width,\n",
    "    label='Con Complicanze',\n",
    "    color='lightcoral',\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Aggiunta etichette numeriche sopra le barre\n",
    "for bars in (bar1, bar2):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width()/2,\n",
    "                h + 0.5,\n",
    "                str(int(h)),\n",
    "                ha='center', va='bottom', fontsize=9\n",
    "            )\n",
    "\n",
    "plt.xticks(index, [str(i) for i in conta_per_interval.index], rotation=45)\n",
    "plt.xlabel('%TIR')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 7) TEST STATISTICO MANN–WHITNEY U\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "g0 = tir_by_paziente.loc[~tir_by_paziente['Has_Diagnosis'], '%TIR']\n",
    "g1 = tir_by_paziente.loc[ tir_by_paziente['Has_Diagnosis'], '%TIR']\n",
    "u_stat, p_value = mannwhitneyu(g0, g1, alternative='two-sided')\n",
    "print(f\"U-statistic = {u_stat:.2f}\")\n",
    "print(f\"p-value      = {p_value:.4f}\")\n",
    "\n",
    "# STATISTICHE PER GRUPPO\n",
    "for nome_gruppo, gruppo in zip([\"Senza Complicanze\", \"Con Complicanze\"], [g0, g1]):\n",
    "    media   = gruppo.mean()\n",
    "    mediana = gruppo.median()\n",
    "    q1      = gruppo.quantile(0.25)\n",
    "    q3      = gruppo.quantile(0.75)\n",
    "    iqr     = q3 - q1\n",
    "\n",
    "    print(f\"\\nStatistiche per il gruppo '{nome_gruppo}':\")\n",
    "    print(f\" - Media:   {media:.2f}\")\n",
    "    print(f\" - Mediana: {mediana:.2f}\")\n",
    "    print(f\" - IQR:     {iqr:.2f} (Q3: {q3:.2f}, Q1: {q1:.2f})\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 8) STATISTICHE AGGIUNTIVE: MEDIA, MEDIANA, ASIMMETRIA, CURTOSI, OUTLIER, MODA\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "tir_values = tir_by_paziente['%TIR']\n",
    "media    = tir_values.mean()\n",
    "mediana  = tir_values.median()\n",
    "asim     = skew(tir_values)\n",
    "curto    = kurtosis(tir_values)\n",
    "moda     = tir_values.round().mode()\n",
    "q1, q3   = tir_values.quantile([0.25, 0.75])\n",
    "iqr      = q3 - q1\n",
    "outliers = tir_values[\n",
    "    (tir_values < q1 - 1.5 * iqr) |\n",
    "    (tir_values > q3 + 1.5 * iqr)\n",
    "]\n",
    "\n",
    "print(f\"Media: {media:.2f}\")\n",
    "print(f\"Mediana: {mediana:.2f}\")\n",
    "print(f\"Asimmetria (skewness): {asim:.2f}\")\n",
    "print(f\"Curtosi (kurtosis): {curto:.2f}\")\n",
    "print(f\"Numero di outlier: {len(outliers)}\")\n",
    "print(\"Moda:\", moda.tolist())\n",
    "\n",
    "q1_total, q3_total = tir_values.quantile([0.25, 0.75])\n",
    "iqr_total = q3_total - q1_total\n",
    "print(f\"Q1:  {q1_total:.2f}\")\n",
    "print(f\"Q3:  {q3_total:.2f}\")\n",
    "print(f\"IQR: {iqr_total:.2f}\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 9) CALCOLO TIR SUI PRIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date']) # trasforma la colonna Measurement_date del glucosio in oggetti datetime\n",
    "first_dates = df.groupby('Patient_ID')['Measurement_date'].min().rename('FirstDate')    # per ogni paziente calcola la data della prima misurazione\n",
    "df = df.join(first_dates, on='Patient_ID')  # aggiunge al dataset di partenza la colonna che indica la prima data di misurazione del glucosio\n",
    "\n",
    "df_3m = df[df['Measurement_date'] <= df['FirstDate'] + pd.DateOffset(months=3)] #crea un sotto-dataset che cotiene solo le righe in cui la data di misurazione é ≤ (prima data + 3 mesi)\n",
    "pazienti_3m = df_3m.groupby('Patient_ID')   # ragruppa il risultato per paziente\n",
    "tir3m_by_paziente = pazienti_3m.apply(      # sul dataset ottenuto che contiene solo i primi 3 mesi di misurazioni per paziente calcola il TIR e lo aggiunge come colonna\n",
    "    calculate_tir,\n",
    "    include_groups=False              # evita warning anche qui\n",
    ").reset_index(name='%TIR_3m')\n",
    "\n",
    "# Al dataset aggiunge anche il campo Has_Diagnosis che indica se il paziente ha o meno una complicanza\n",
    "tir3m_by_paziente['Has_Diagnosis'] = tir3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "tir3m_by_paziente['Interval'] = pd.cut(     # raggruppa i valori di TIR in intervalli da 10\n",
    "    tir3m_by_paziente['%TIR_3m'],\n",
    "    bins=bins,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "\n",
    "conta_per_interval_3m = (\n",
    "    tir3m_by_paziente\n",
    "      .groupby(\n",
    "          ['Interval', 'Has_Diagnosis'],\n",
    "          observed=False              # evita FutureWarning anche qui\n",
    "      )\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# Istogramma primi 3 mesi\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_3m = list(range(len(conta_per_interval_3m)))\n",
    "\n",
    "bar1_3m = plt.bar(\n",
    "    [i - bar_width/2 for i in index_3m],\n",
    "    conta_per_interval_3m[False],\n",
    "    width=bar_width,\n",
    "    label='Senza Complicanze', edgecolor='black', color='skyblue',\n",
    ")\n",
    "bar2_3m = plt.bar(\n",
    "    [i + bar_width/2 for i in index_3m],\n",
    "    conta_per_interval_3m[True],\n",
    "    width=bar_width,\n",
    "    label='Con Complicanze', edgecolor='black', color='lightcoral',\n",
    ")\n",
    "for bars in (bar1_3m, bar2_3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, h + 0.5,\n",
    "                     str(int(h)), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(index_3m, [str(i) for i in conta_per_interval_3m.index], rotation=45)\n",
    "plt.xlabel('%TIR_3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche descrittive %TIR_3m\n",
    "print(tir3m_by_paziente['%TIR_3m'].describe())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 10) CALCOLO TIR SUGLI ULTIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date'])  # datetime\n",
    "# Calcolo per ogni paziente la data dell'ultima misurazione\n",
    "last_dates = df.groupby('Patient_ID')['Measurement_date'].max().rename('LastDate')\n",
    "# Aggiungo la colonna LastDate al dataset\n",
    "df = df.join(last_dates, on='Patient_ID')\n",
    "\n",
    "# Filtro alle righe in cui la data di misurazione è ≥ (ultima data - 3 mesi)\n",
    "df_last3m = df[df['Measurement_date'] >= df['LastDate'] - pd.DateOffset(months=3)]\n",
    "# Raggruppo per paziente\n",
    "pazienti_last3m = df_last3m.groupby('Patient_ID')\n",
    "\n",
    "# Calcolo %TIR sugli ultimi 3 mesi per ciascun paziente\n",
    "tir_last3m_by_paziente = pazienti_last3m.apply(\n",
    "    calculate_tir,\n",
    "    include_groups=False\n",
    ").reset_index(name='%TIR_last3m')\n",
    "\n",
    "# Merge sul Patient_ID\n",
    "parte1 = parte1.merge(\n",
    "    tir_last3m_by_paziente[['Patient_ID', '%TIR_last3m']],\n",
    "    on='Patient_ID',\n",
    "    how='left',\n",
    "    validate='one_to_one'    # assicura che ogni paziente appaia una sola volta in entrambi\n",
    ")\n",
    "\n",
    "# Controlla eventuali pazienti senza misurazioni negli ultimi 3 mesi\n",
    "missing_l3m = parte1['%TIR_last3m'].isna().sum()\n",
    "if missing_l3m > 0:\n",
    "    print(f\"Attenzione: {missing_l3m} pazienti non hanno misurazioni negli ultimi 3 mesi e avranno %TIR_last3m=NaN\")\n",
    "\n",
    "# Salva il risultato senza formattazione particolare\n",
    "parte1.to_csv(\"Excel/Parte1.csv\", index=False)\n",
    "print(\"Aggiornato Excel/Parte1.csv con la colonna %TIR_last3m.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Aggiungo flag complicanze e fasce di %TIR\n",
    "tir_last3m_by_paziente['Has_Diagnosis'] = tir_last3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "tir_last3m_by_paziente['Interval'] = pd.cut(\n",
    "    tir_last3m_by_paziente['%TIR_last3m'],\n",
    "    bins=bins,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# Conteggio per intervallo e condizione\n",
    "conta_per_interval_last3m = (\n",
    "    tir_last3m_by_paziente\n",
    "      .groupby(['Interval', 'Has_Diagnosis'], observed=False)\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# Istogramma ultimi 3 mesi\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_l3m = range(len(conta_per_interval_last3m))\n",
    "\n",
    "bar1_l3m = plt.bar(\n",
    "    [i - bar_width/2 for i in index_l3m],\n",
    "    conta_per_interval_last3m[False],\n",
    "    width=bar_width,\n",
    "    label='Senza Complicanze', edgecolor='black', color='skyblue'\n",
    ")\n",
    "bar2_l3m = plt.bar(\n",
    "    [i + bar_width/2 for i in index_l3m],\n",
    "    conta_per_interval_last3m[True],\n",
    "    width=bar_width,\n",
    "    label='Con Complicanze', edgecolor='black', color='lightcoral'\n",
    ")\n",
    "for bars in (bar1_l3m, bar2_l3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width()/2,\n",
    "                h + 0.5,\n",
    "                str(int(h)),\n",
    "                ha='center', va='bottom', fontsize=9\n",
    "            )\n",
    "\n",
    "plt.xticks(index_l3m, [str(i) for i in conta_per_interval_last3m.index], rotation=45)\n",
    "plt.xlabel('%TIR_last3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche descrittive %TIR_last3m\n",
    "print(tir_last3m_by_paziente['%TIR_last3m'].describe())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# 11) TEST STATISTICO MANN–WHITNEY U: confronto TIR primi 3 mesi vs ultimi 3 mesi\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Estrazione delle due distribuzioni\n",
    "tir_first3m = tir3m_by_paziente['%TIR_3m']\n",
    "tir_last3m  = tir_last3m_by_paziente['%TIR_last3m']\n",
    "\n",
    "# Mann–Whitney U test (two-sided)\n",
    "u_stat_3m, p_value_3m = mannwhitneyu(tir_first3m, tir_last3m, alternative='two-sided')\n",
    "\n",
    "print(\"Confronto TIR Primi 3 Mesi vs Ultimi 3 Mesi\")\n",
    "print(f\" U-statistic = {u_stat_3m:.2f}\")\n",
    "print(f\" p-value      = {p_value_3m:.4f}\")\n",
    "\n",
    "# Eventuale interpretazione\n",
    "alpha = 0.05\n",
    "if p_value_3m < alpha:\n",
    "    print(\"→ Differenza statisticamente significativa (rifiutiamo H0 a α=0.05).\")\n",
    "else:\n",
    "    print(\"→ Nessuna differenza statisticamente significativa (non rifiutiamo H0 a α=0.05).\")\n",
    "\n",
    "\n",
    "############################################################################################"
   ],
   "id": "5856924cbf5a2b6e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "df = pd.read_csv(\"Excel/Glucose_measurements.csv\")\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "\n",
    "# ANALISI TAR\n",
    "############################################################################################\n",
    "# Funzione per calcolare il TAR di un paziente\n",
    "def calculate_tar(misurazioni): # Prende in ingresso l'insieme di misurazioni di un singolo paziente\n",
    "    totale = len(misurazioni)   # Calcola il numero totale di misurazioni del paziente\n",
    "    righe_valide = misurazioni[(misurazioni['Measurement'] > 180)] # Seleziona solo le righe che nel campo Measurement hanno un valore maggiore di 180 mg/dL\n",
    "    tar = len(righe_valide)/totale * 100 # Calcola il %TAR facendo Misurazioni Valide/Misurazioni Totali\n",
    "    return tar\n",
    "\n",
    "pazienti = df.groupby('Patient_ID') # Dividiamo il dataset per paziente, ogni gruppo contiene le misurazioni di un singolo paziente\n",
    "tar_by_paziente = pazienti.apply(calculate_tar,include_groups=False ).reset_index(name='%TAR') # Calcoliamo il TAR di ogni paziente e creiamo un nuovo dataset con 2 colonne: Ptient_ID e %TAR\n",
    "# tar_by_paziente = tar_by_paziente.sort_values(by='%TAR', ascending=False)\n",
    "\n",
    "print(tar_by_paziente)\n",
    "\n",
    "# Grafico per la percentuale di ogni paziente\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(tar_by_paziente['Patient_ID'], tar_by_paziente['%TAR'], color='skyblue')\n",
    "plt.xticks([])\n",
    "plt.ylabel('% Time Above Range (> 180 mg/dL)')\n",
    "plt.xlabel('Pazienti')\n",
    "plt.title('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche descrittive di %TAR\n",
    "print(tar_by_paziente['%TAR'].describe())\n",
    "\n",
    "bins = [0, 1] + list(range(10, 110, 10))\n",
    "tar_intervals = pd.cut(tar_by_paziente['%TAR'], bins=bins, right=False)\n",
    "#Notazione [0,10) 0 é incluso ma 10 no\n",
    "\n",
    "# Aggiungiamo colonna per sapere se il paziente ha almeno una diagnosi\n",
    "pazienti_con_diagnosi = set(diagnostics['Patient_ID'])\n",
    "tar_by_paziente['Has_Diagnosis'] = tar_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# Aggiungiamo anche gli intervalli nel dataframe\n",
    "tar_by_paziente['Interval'] = tar_intervals\n",
    "\n",
    "# Calcoliamo il numero di pazienti CON e SENZA diagnosi per ogni intervallo\n",
    "conta_per_interval = tar_by_paziente.groupby(['Interval', 'Has_Diagnosis'],observed=False  ).size().unstack(fill_value=0)\n",
    "conta_per_interval = conta_per_interval.sort_index()\n",
    "\n",
    "# Istogramma con due barre affiancate per ogni intervallo, con etichette\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index = range(len(conta_per_interval))\n",
    "\n",
    "bar1 = plt.bar([i - bar_width/2 for i in index], conta_per_interval[False], width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2 = plt.bar([i + bar_width/2 for i in index], conta_per_interval[True], width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "# Aggiunta delle etichette numeriche sopra ogni barra\n",
    "for bars in [bar1, bar2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "\n",
    "plt.xticks(index, [str(i) for i in conta_per_interval.index], rotation=45)\n",
    "plt.xlabel('%TAR')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "tar_values = tar_by_paziente['%TAR']\n",
    "\n",
    "# Statistiche descrittive\n",
    "media = tar_values.mean()\n",
    "mediana = tar_values.median()\n",
    "asimmetria = skew(tar_values) #skewness\n",
    "curtosi = kurtosis(tar_values)\n",
    "\n",
    "tar_arrotondato = tar_values.round()\n",
    "moda = tar_arrotondato.mode()\n",
    "\n",
    "# Outlier con metodo IQR (Interquartile Range)\n",
    "# calcola Q1, Q3 e IQR\n",
    "q1 = tar_values.quantile(0.25)\n",
    "q3 = tar_values.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# soglie per outlier\n",
    "lower_thr = q1 - 1.5 * iqr\n",
    "upper_thr = q3 + 1.5 * iqr\n",
    "\n",
    "print(f\"Q1 = {q1:.2f}%, Q3 = {q3:.2f}%, IQR = {iqr:.2f}%\")\n",
    "print(f\"Soglia inferiore = {lower_thr:.2f}%, soglia superiore = {upper_thr:.2f}%\")\n",
    "outliers = tar_values[(tar_values < lower_thr) | (tar_values > upper_thr)]\n",
    "print(\"Valori TAR considerati outlier:\")\n",
    "print(outliers.sort_values().to_list())\n",
    "\n",
    "\n",
    "\n",
    "# Output\n",
    "print(f\"Media: {media:.2f}\")\n",
    "print(f\"Mediana: {mediana:.2f}\")\n",
    "print(f\"Asimmetria (skewness): {asimmetria:.2f}\")\n",
    "print(f\"Curtosi (kurtosis): {curtosi:.2f}\")\n",
    "print(f\"Numero di outlier: {len(outliers)}\")\n",
    "print(\"Moda:\", moda.tolist())\n",
    "\n",
    "\n",
    "# Estrai le due serie\n",
    "g0 = tar_by_paziente.loc[ tar_by_paziente['Has_Diagnosis']==False, '%TAR']\n",
    "g1 = tar_by_paziente.loc[ tar_by_paziente['Has_Diagnosis']==True,  '%TAR']\n",
    "\n",
    "# Esegui il test two-sided\n",
    "u_stat, p_value = mannwhitneyu(g0, g1, alternative='two-sided')\n",
    "\n",
    "print(f\"U-statistic = {u_stat:.2f}\")\n",
    "print(f\"p-value      = {p_value:.4f}\")\n",
    "\n",
    "# STATISTICHE PER GRUPPO\n",
    "for nome_gruppo, gruppo in zip([\"Senza Complicanze\", \"Con Complicanze\"], [g0, g1]):\n",
    "    media   = gruppo.mean()\n",
    "    mediana = gruppo.median()\n",
    "    q1      = gruppo.quantile(0.25)\n",
    "    q3      = gruppo.quantile(0.75)\n",
    "    iqr     = q3 - q1\n",
    "\n",
    "    print(f\"\\nStatistiche per il gruppo '{nome_gruppo}':\")\n",
    "    print(f\" - Media:   {media:.2f}\")\n",
    "    print(f\" - Mediana: {mediana:.2f}\")\n",
    "    print(f\" - IQR:     {iqr:.2f} (Q3: {q3:.2f}, Q1: {q1:.2f})\")\n",
    "############################################################################################"
   ],
   "id": "17dfa5ab0040f43e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# ANALISI TAR LV1\n",
    "############################################################################################\n",
    "\n",
    "parte1 = pd.read_csv(\"Excel/Parte1.csv\")\n",
    "df = pd.read_csv(\"Excel/Glucose_measurements.csv\")\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "\n",
    "# Funzione per calcolare il TARLV1 di un paziente\n",
    "def calculate_tar(misurazioni): # Prende in ingresso l'insieme di misurazioni di un singolo paziente\n",
    "    totale = len(misurazioni)   # Calcola il numero totale di misurazioni del paziente\n",
    "    righe_valide = misurazioni[(misurazioni['Measurement'] >= 181) & (misurazioni['Measurement'] <= 249)] # Seleziona solo le righe che nel campo Measurement hanno un valore compreso tra 181 e 249 mg/dL\n",
    "    tar = len(righe_valide)/totale * 100 # Calcola il %TARLV1 facendo Misurazioni Valide/Misurazioni Totali\n",
    "    return tar\n",
    "\n",
    "pazienti = df.groupby('Patient_ID') # Dividiamo il dataset per paziente, ogni gruppo contiene le misurazioni di un singolo paziente\n",
    "tar_by_paziente = pazienti.apply(calculate_tar, include_groups=False).reset_index(name='%TARLV1') # Calcoliamo il TARLV1 di ogni paziente e creiamo un nuovo dataset con 2 colonne: Ptient_ID e %TARLV1\n",
    "# tar_by_paziente = tar_by_paziente.sort_values(by='%TARLV1', ascending=False)\n",
    "\n",
    "print(tar_by_paziente)\n",
    "\n",
    "# Grafico per la percentuale di ogni paziente\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(tar_by_paziente['Patient_ID'], tar_by_paziente['%TARLV1'], color='#ffa07a')\n",
    "plt.xticks([])\n",
    "plt.ylabel('% Time Above Range LV1 (181 - 249 mg/dL)')\n",
    "plt.xlabel('Pazienti')\n",
    "plt.title('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche descrittive di %TARLV1\n",
    "print(tar_by_paziente['%TARLV1'].describe())\n",
    "\n",
    "bins = [0, 1] + list(range(10, 110, 10))\n",
    "tar_intervals = pd.cut(tar_by_paziente['%TARLV1'], bins=bins, right=False)\n",
    "#Notazione [0,10) 0 é incluso ma 10 no\n",
    "\n",
    "# Aggiungiamo colonna per sapere se il paziente ha almeno una diagnosi\n",
    "pazienti_con_diagnosi = set(diagnostics['Patient_ID'])\n",
    "tar_by_paziente['Has_Diagnosis'] = tar_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# Aggiungiamo anche gli intervalli nel dataframe\n",
    "tar_by_paziente['Interval'] = tar_intervals\n",
    "\n",
    "# Calcoliamo il numero di pazienti CON e SENZA diagnosi per ogni intervallo\n",
    "conta_per_interval = tar_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0)\n",
    "conta_per_interval = conta_per_interval.sort_index()\n",
    "\n",
    "\n",
    "# Istogramma con due barre affiancate per ogni intervallo, con etichette\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index = range(len(conta_per_interval))\n",
    "\n",
    "bar1 = plt.bar([i - bar_width/2 for i in index], conta_per_interval[False], width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2 = plt.bar([i + bar_width/2 for i in index], conta_per_interval[True], width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "# Aggiunta delle etichette numeriche sopra ogni barra\n",
    "for bars in [bar1, bar2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "\n",
    "plt.xticks(index, [str(i) for i in conta_per_interval.index], rotation=45)\n",
    "plt.xlabel('%TARLV1')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tar_values = tar_by_paziente['%TARLV1']\n",
    "\n",
    "# Statistiche descrittive\n",
    "media = tar_values.mean()\n",
    "mediana = tar_values.median()\n",
    "asimmetria = skew(tar_values) #skewness\n",
    "curtosi = kurtosis(tar_values)\n",
    "\n",
    "tar_arrotondato = tar_values.round()\n",
    "moda = tar_arrotondato.mode()\n",
    "\n",
    "# Outlier con metodo IQR (Interquartile Range)\n",
    "# calcola Q1, Q3 e IQR\n",
    "q1 = tar_values.quantile(0.25)\n",
    "q3 = tar_values.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# soglie per outlier\n",
    "lower_thr = q1 - 1.5 * iqr\n",
    "upper_thr = q3 + 1.5 * iqr\n",
    "\n",
    "print(f\"Q1 = {q1:.2f}%, Q3 = {q3:.2f}%, IQR = {iqr:.2f}%\")\n",
    "print(f\"Soglia inferiore = {lower_thr:.2f}%, soglia superiore = {upper_thr:.2f}%\")\n",
    "outliers = tar_values[(tar_values < lower_thr) | (tar_values > upper_thr)]\n",
    "print(\"Valori TARLV1 considerati outlier:\")\n",
    "print(outliers.sort_values().to_list())\n",
    "\n",
    "\n",
    "\n",
    "# Output\n",
    "print(f\"Media: {media:.2f}\")\n",
    "print(f\"Mediana: {mediana:.2f}\")\n",
    "print(f\"Asimmetria (skewness): {asimmetria:.2f}\")\n",
    "print(f\"Curtosi (kurtosis): {curtosi:.2f}\")\n",
    "print(f\"Numero di outlier: {len(outliers)}\")\n",
    "print(\"Moda:\", moda.tolist())\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# CALCOLO TAR SUI PRIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1) Converto Measurement_date in datetime\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date'])\n",
    "\n",
    "# 2) Calcolo la prima data di misurazione per ogni paziente\n",
    "first_dates = df.groupby('Patient_ID')['Measurement_date'].min().rename('FirstDate')\n",
    "df = df.join(first_dates, on='Patient_ID')\n",
    "\n",
    "# 3) Seleziono misurazioni entro 3 mesi dalla data iniziale\n",
    "df_3m = df[df['Measurement_date'] <= df['FirstDate'] + pd.DateOffset(months=3)]\n",
    "\n",
    "# 4) Calcolo il TIR sui primi 3 mesi\n",
    "pazienti_3m = df_3m.groupby('Patient_ID')\n",
    "tar3m_by_paziente = pazienti_3m.apply(calculate_tar, include_groups=False ).reset_index(name='%TARLV1_3m')\n",
    "\n",
    "# 5) Aggiungo il flag di diagnosi\n",
    "tar3m_by_paziente['Has_Diagnosis'] = tar3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# 6) Creo gli stessi intervalli usati prima su %TIR_3m\n",
    "tar3m_by_paziente['Interval'] = pd.cut(tar3m_by_paziente['%TARLV1_3m'], bins=bins, right=False)\n",
    "\n",
    "# 7) Raggruppo e conto\n",
    "conta_per_interval_3m = tar3m_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "# 8) Disegno l’istogramma a barre affiancate\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_3m = range(len(conta_per_interval_3m))\n",
    "\n",
    "bar1_3m = plt.bar([i - bar_width/2 for i in index_3m], conta_per_interval_3m[False],\n",
    "                   width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2_3m = plt.bar([i + bar_width/2 for i in index_3m], conta_per_interval_3m[True],\n",
    "                   width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "for bars in (bar1_3m, bar2_3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, h + 0.5, str(int(h)),\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(index_3m, [str(i) for i in conta_per_interval_3m.index], rotation=45)\n",
    "plt.xlabel('%TARLV1_3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9) Statistiche descrittive per %TIR_3m (facoltativo)\n",
    "print(tar3m_by_paziente['%TARLV1_3m'].describe())\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# CALCOLO TAR SUGLI ULTIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1) Converto Measurement_date in datetime\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date'])\n",
    "\n",
    "# 2) Calcolo l'ultima data di misurazione per ogni paziente\n",
    "first_dates = df.groupby('Patient_ID')['Measurement_date'].max().rename('LastDate')\n",
    "df = df.join(first_dates, on='Patient_ID')\n",
    "\n",
    "# 3) Seleziono misurazioni entro 3 mesi dalla data finale\n",
    "df_3m = df[df['Measurement_date'] >= df['LastDate'] - pd.DateOffset(months=3)]\n",
    "\n",
    "# 4) Calcolo il TIR sugli ultimi 3 mesi\n",
    "pazienti_3m = df_3m.groupby('Patient_ID')\n",
    "tar_last3m_by_paziente = pazienti_3m.apply(calculate_tar, include_groups=False ).reset_index(name='%TARLV1_last3m')\n",
    "\n",
    "# Merge con i valori %TARLV1_last3m calcolati\n",
    "parte1 = parte1.merge(\n",
    "    tar_last3m_by_paziente[['Patient_ID', '%TARLV1_last3m']],\n",
    "    on='Patient_ID',\n",
    "    how='left',\n",
    "    validate='one_to_one'  # verifica che non ci siano duplicati\n",
    ")\n",
    "\n",
    "# Opzionale: controlla quanti pazienti non hanno %TARLV1_last3m (nessuna misurazione negli ultimi 3 mesi)\n",
    "missing = parte1['%TARLV1_last3m'].isna().sum()\n",
    "print(f\"Attenzione: {missing} pazienti non hanno misurazioni negli ultimi 3 mesi.\")\n",
    "\n",
    "# Salva il dataset aggiornato\n",
    "parte1.to_csv(\"Excel/Parte1.csv\", index=False)\n",
    "print(\"✅ Salvato 'Excel/Parte1.csv' con la nuova colonna '%TARLV1_last3m'.\")\n",
    "\n",
    "# 5) Aggiungo il flag di diagnosi\n",
    "tar_last3m_by_paziente['Has_Diagnosis'] = tar_last3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# 6) Creo gli stessi intervalli usati prima su %TIR_3m\n",
    "tar_last3m_by_paziente['Interval'] = pd.cut(tar_last3m_by_paziente['%TARLV1_last3m'], bins=bins, right=False)\n",
    "\n",
    "# 7) Raggruppo e conto\n",
    "conta_per_interval_3m = tar_last3m_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "# 8) Disegno l’istogramma a barre affiancate\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_3m = range(len(conta_per_interval_3m))\n",
    "\n",
    "bar1_3m = plt.bar([i - bar_width/2 for i in index_3m], conta_per_interval_3m[False],\n",
    "                   width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2_3m = plt.bar([i + bar_width/2 for i in index_3m], conta_per_interval_3m[True],\n",
    "                   width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "for bars in (bar1_3m, bar2_3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, h + 0.5, str(int(h)),\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(index_3m, [str(i) for i in conta_per_interval_3m.index], rotation=45)\n",
    "plt.xlabel('%TARLV1_last3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9) Statistiche descrittive per %TIR_3m (facoltativo)\n",
    "print(tar_last3m_by_paziente['%TARLV1_last3m'].describe())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# TEST STATISTICO MANN–WHITNEY U: confronto TAR primi 3 mesi vs ultimi 3 mesi\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Estrazione delle due distribuzioni\n",
    "tar_first3m = tar3m_by_paziente['%TARLV1_3m']\n",
    "tar_last3m  = tar_last3m_by_paziente['%TARLV1_last3m']\n",
    "\n",
    "# Mann–Whitney U test (two-sided)\n",
    "u_stat_3m, p_value_3m = mannwhitneyu(tar_first3m, tar_last3m, alternative='two-sided')\n",
    "\n",
    "print(\"Confronto TAR Primi 3 Mesi vs Ultimi 3 Mesi\")\n",
    "print(f\" U-statistic = {u_stat_3m:.2f}\")\n",
    "print(f\" p-value      = {p_value_3m:.4f}\")\n",
    "\n",
    "# Eventuale interpretazione\n",
    "alpha = 0.05\n",
    "if p_value_3m < alpha:\n",
    "    print(\"→ Differenza statisticamente significativa (rifiutiamo H0 a α=0.05).\")\n",
    "else:\n",
    "    print(\"→ Nessuna differenza statisticamente significativa (non rifiutiamo H0 a α=0.05).\")\n",
    "\n",
    "############################################################################################"
   ],
   "id": "70860fb7ac8aa435"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "df = pd.read_csv(\"Excel/Glucose_measurements.csv\")\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "parte1 = pd.read_csv(\"Excel/Parte1.csv\")\n",
    "\n",
    "# ANALISI TAR LV2\n",
    "############################################################################################\n",
    "# Funzione per calcolare il TARLV2 di un paziente\n",
    "def calculate_tar(misurazioni): # Prende in ingresso l'insieme di misurazioni di un singolo paziente\n",
    "    totale = len(misurazioni)   # Calcola il numero totale di misurazioni del paziente\n",
    "    righe_valide = misurazioni[(misurazioni['Measurement'] >= 250)] # Seleziona solo le righe che nel campo Measurement hanno un valore maggiore di 250 mg/dL\n",
    "    tar = len(righe_valide)/totale * 100 # Calcola il %TARLV2 facendo Misurazioni Valide/Misurazioni Totali\n",
    "    return tar\n",
    "\n",
    "pazienti = df.groupby('Patient_ID') # Dividiamo il dataset per paziente, ogni gruppo contiene le misurazioni di un singolo paziente\n",
    "tar_by_paziente = pazienti.apply(calculate_tar, include_groups=False).reset_index(name='%TARLV2') # Calcoliamo il TARLV2 di ogni paziente e creiamo un nuovo dataset con 2 colonne: Ptient_ID e %TARLV2\n",
    "# tar_by_paziente = tar_by_paziente.sort_values(by='%TARLV2', ascending=False)\n",
    "\n",
    "print(tar_by_paziente)\n",
    "\n",
    "# Grafico per la percentuale di ogni paziente\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(tar_by_paziente['Patient_ID'], tar_by_paziente['%TARLV2'], color='#e64100')\n",
    "plt.xticks([])\n",
    "plt.ylabel('% Time Above Range LV2 (> 249 mg/dL)')\n",
    "plt.xlabel('Pazienti')\n",
    "plt.title('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche descrittive di %TARLV2\n",
    "print(tar_by_paziente['%TARLV2'].describe())\n",
    "\n",
    "bins = [0, 1] + list(range(10, 110, 10))\n",
    "tar_intervals = pd.cut(tar_by_paziente['%TARLV2'], bins=bins, right=False)\n",
    "#Notazione [0,10) 0 é incluso ma 10 no\n",
    "\n",
    "# Aggiungiamo colonna per sapere se il paziente ha almeno una diagnosi\n",
    "pazienti_con_diagnosi = set(diagnostics['Patient_ID'])\n",
    "tar_by_paziente['Has_Diagnosis'] = tar_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# Aggiungiamo anche gli intervalli nel dataframe\n",
    "tar_by_paziente['Interval'] = tar_intervals\n",
    "\n",
    "# Calcoliamo il numero di pazienti CON e SENZA diagnosi per ogni intervallo\n",
    "conta_per_interval = tar_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0)\n",
    "conta_per_interval = conta_per_interval.sort_index()\n",
    "\n",
    "# Istogramma con due barre affiancate per ogni intervallo, con etichette\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index = range(len(conta_per_interval))\n",
    "\n",
    "bar1 = plt.bar([i - bar_width/2 for i in index], conta_per_interval[False], width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2 = plt.bar([i + bar_width/2 for i in index], conta_per_interval[True], width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "# Aggiunta delle etichette numeriche sopra ogni barra\n",
    "for bars in [bar1, bar2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "\n",
    "plt.xticks(index, [str(i) for i in conta_per_interval.index], rotation=45)\n",
    "plt.xlabel('%TARLV2')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tar_values = tar_by_paziente['%TARLV2']\n",
    "\n",
    "# Statistiche descrittive\n",
    "media = tar_values.mean()\n",
    "mediana = tar_values.median()\n",
    "asimmetria = skew(tar_values) #skewness\n",
    "curtosi = kurtosis(tar_values)\n",
    "\n",
    "tar_arrotondato = tar_values.round()\n",
    "moda = tar_arrotondato.mode()\n",
    "\n",
    "# Outlier con metodo IQR (Interquartile Range)\n",
    "# calcola Q1, Q3 e IQR\n",
    "q1 = tar_values.quantile(0.25)\n",
    "q3 = tar_values.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# soglie per outlier\n",
    "lower_thr = q1 - 1.5 * iqr\n",
    "upper_thr = q3 + 1.5 * iqr\n",
    "\n",
    "print(f\"Q1 = {q1:.2f}%, Q3 = {q3:.2f}%, IQR = {iqr:.2f}%\")\n",
    "print(f\"Soglia inferiore = {lower_thr:.2f}%, soglia superiore = {upper_thr:.2f}%\")\n",
    "outliers = tar_values[(tar_values < lower_thr) | (tar_values > upper_thr)]\n",
    "print(\"Valori TARLV2 considerati outlier:\")\n",
    "print(outliers.sort_values().to_list())\n",
    "\n",
    "\n",
    "\n",
    "# Output\n",
    "print(f\"Media: {media:.2f}\")\n",
    "print(f\"Mediana: {mediana:.2f}\")\n",
    "print(f\"Asimmetria (skewness): {asimmetria:.2f}\")\n",
    "print(f\"Curtosi (kurtosis): {curtosi:.2f}\")\n",
    "print(f\"Numero di outlier: {len(outliers)}\")\n",
    "print(\"Moda:\", moda.tolist())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# CALCOLO TAR SUI PRIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# 1) Converto Measurement_date in datetime\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date'])\n",
    "\n",
    "# 2) Calcolo la prima data di misurazione per ogni paziente\n",
    "first_dates = df.groupby('Patient_ID')['Measurement_date'].min().rename('FirstDate')\n",
    "df = df.join(first_dates, on='Patient_ID')\n",
    "\n",
    "# 3) Seleziono misurazioni entro 3 mesi dalla data iniziale\n",
    "df_3m = df[df['Measurement_date'] <= df['FirstDate'] + pd.DateOffset(months=3)]\n",
    "\n",
    "# 4) Calcolo il TIR sui primi 3 mesi\n",
    "pazienti_3m = df_3m.groupby('Patient_ID')\n",
    "tar3m_by_paziente = pazienti_3m.apply(calculate_tar, include_groups=False).reset_index(name='%TARLV2_3m')\n",
    "\n",
    "# 5) Aggiungo il flag di diagnosi\n",
    "tar3m_by_paziente['Has_Diagnosis'] = tar3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# 6) Creo gli stessi intervalli usati prima su %TIR_3m\n",
    "tar3m_by_paziente['Interval'] = pd.cut(tar3m_by_paziente['%TARLV2_3m'], bins=bins, right=False)\n",
    "\n",
    "# 7) Raggruppo e conto\n",
    "conta_per_interval_3m = tar3m_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "# 8) Disegno l’istogramma a barre affiancate\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_3m = range(len(conta_per_interval_3m))\n",
    "\n",
    "bar1_3m = plt.bar([i - bar_width/2 for i in index_3m], conta_per_interval_3m[False],\n",
    "                   width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2_3m = plt.bar([i + bar_width/2 for i in index_3m], conta_per_interval_3m[True],\n",
    "                   width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "for bars in (bar1_3m, bar2_3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, h + 0.5, str(int(h)),\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(index_3m, [str(i) for i in conta_per_interval_3m.index], rotation=45)\n",
    "plt.xlabel('%TARLV2_3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9) Statistiche descrittive per %TIR_3m (facoltativo)\n",
    "print(tar3m_by_paziente['%TARLV2_3m'].describe())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# CALCOLO TAR SUGLI ULTIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1) Converto Measurement_date in datetime\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date'])\n",
    "\n",
    "# 2) Calcolo l'ultima data di misurazione per ogni paziente\n",
    "first_dates = df.groupby('Patient_ID')['Measurement_date'].max().rename('LastDate')\n",
    "df = df.join(first_dates, on='Patient_ID')\n",
    "\n",
    "# 3) Seleziono misurazioni entro 3 mesi dalla data finale\n",
    "df_3m = df[df['Measurement_date'] >= df['LastDate'] - pd.DateOffset(months=3)]\n",
    "\n",
    "# 4) Calcolo il TIR sugli ultimi 3 mesi\n",
    "pazienti_3m = df_3m.groupby('Patient_ID')\n",
    "tar_last3m_by_paziente = pazienti_3m.apply(calculate_tar, include_groups=False ).reset_index(name='%TARLV2_last3m')\n",
    "\n",
    "# Merge con i valori %TARLV2_last3m calcolati\n",
    "parte1 = parte1.merge(\n",
    "    tar_last3m_by_paziente[['Patient_ID', '%TARLV2_last3m']],\n",
    "    on='Patient_ID',\n",
    "    how='left',\n",
    "    validate='one_to_one'  # Assicura corrispondenza 1-a-1\n",
    ")\n",
    "\n",
    "# Controllo eventuali NaN\n",
    "missing = parte1['%TARLV2_last3m'].isna().sum()\n",
    "print(f\"Attenzione: {missing} pazienti non hanno misurazioni per il calcolo del TAR livello 2 negli ultimi 3 mesi.\")\n",
    "\n",
    "# Salvataggio del dataset aggiornato\n",
    "parte1.to_csv(\"Excel/Parte1.csv\", index=False)\n",
    "print(\"✅ Salvato 'Excel/Parte1.csv' con la nuova colonna '%TARLV2_last3m'.\")\n",
    "\n",
    "# 5) Aggiungo il flag di diagnosi\n",
    "tar_last3m_by_paziente['Has_Diagnosis'] = tar_last3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# 6) Creo gli stessi intervalli usati prima su %TIR_3m\n",
    "tar_last3m_by_paziente['Interval'] = pd.cut(tar_last3m_by_paziente['%TARLV2_last3m'], bins=bins, right=False)\n",
    "\n",
    "# 7) Raggruppo e conto\n",
    "conta_per_interval_3m = tar_last3m_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "# 8) Disegno l’istogramma a barre affiancate\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_3m = range(len(conta_per_interval_3m))\n",
    "\n",
    "bar1_3m = plt.bar([i - bar_width/2 for i in index_3m], conta_per_interval_3m[False],\n",
    "                   width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2_3m = plt.bar([i + bar_width/2 for i in index_3m], conta_per_interval_3m[True],\n",
    "                   width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "for bars in (bar1_3m, bar2_3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, h + 0.5, str(int(h)),\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(index_3m, [str(i) for i in conta_per_interval_3m.index], rotation=45)\n",
    "plt.xlabel('%TARLV2_last3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9) Statistiche descrittive per %TIR_3m (facoltativo)\n",
    "print(tar_last3m_by_paziente['%TARLV2_last3m'].describe())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# TEST STATISTICO MANN–WHITNEY U: confronto TAR primi 3 mesi vs ultimi 3 mesi\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Estrazione delle due distribuzioni\n",
    "tar_first3m = tar3m_by_paziente['%TARLV2_3m']\n",
    "tar_last3m  = tar_last3m_by_paziente['%TARLV2_last3m']\n",
    "\n",
    "# Mann–Whitney U test (two-sided)\n",
    "u_stat_3m, p_value_3m = mannwhitneyu(tar_first3m, tar_last3m, alternative='two-sided')\n",
    "\n",
    "print(\"Confronto TAR Primi 3 Mesi vs Ultimi 3 Mesi\")\n",
    "print(f\" U-statistic = {u_stat_3m:.2f}\")\n",
    "print(f\" p-value      = {p_value_3m:.4f}\")\n",
    "\n",
    "# Eventuale interpretazione\n",
    "alpha = 0.05\n",
    "if p_value_3m < alpha:\n",
    "    print(\"→ Differenza statisticamente significativa (rifiutiamo H0 a α=0.05).\")\n",
    "else:\n",
    "    print(\"→ Nessuna differenza statisticamente significativa (non rifiutiamo H0 a α=0.05).\")\n",
    "############################################################################################"
   ],
   "id": "c739be48468be3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "df = pd.read_csv(\"Excel/Glucose_measurements.csv\")\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "\n",
    "# ANALISI TBR\n",
    "############################################################################################\n",
    "# Funzione per calcolare il TBR di un paziente\n",
    "def calculate_tbr(misurazioni): # Prende in ingresso l'insieme di misurazioni di un singolo paziente\n",
    "    totale = len(misurazioni)   # Calcola il numero totale di misurazioni del paziente\n",
    "    righe_valide = misurazioni[(misurazioni['Measurement'] < 70)] # Seleziona solo le righe che nel campo Measurement hanno un valore minore di 70 mg/dL\n",
    "    tbr = len(righe_valide)/totale * 100 # Calcola il %TBR facendo Misurazioni Valide/Misurazioni Totali\n",
    "    return tbr\n",
    "\n",
    "pazienti = df.groupby('Patient_ID') # Dividiamo il dataset per paziente, ogni gruppo contiene le misurazioni di un singolo paziente\n",
    "tbr_by_paziente = pazienti.apply(calculate_tbr, include_groups=False).reset_index(name='%TBR') # Calcoliamo il TBR di ogni paziente e creiamo un nuovo dataset con 2 colonne: Ptient_ID e %TBR\n",
    "# tbr_by_paziente = tbr_by_paziente.sort_values(by='%TBR', ascending=False)\n",
    "print(tbr_by_paziente)\n",
    "\n",
    "# Grafico per la percentuale di ogni paziente\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(tbr_by_paziente['Patient_ID'], tbr_by_paziente['%TBR'], color='skyblue')\n",
    "plt.xticks([])\n",
    "plt.ylabel('% Time Below Range (< 70 mg/dL)')\n",
    "plt.xlabel('Pazienti')\n",
    "plt.title('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche descrittive di %TBR\n",
    "print(tbr_by_paziente['%TBR'].describe())\n",
    "\n",
    "bins = [0, 1] + list(range(10, 110, 10))\n",
    "tbr_intervals = pd.cut(tbr_by_paziente['%TBR'], bins=bins, right=False)\n",
    "#Notazione [0,10) 0 é incluso ma 10 no\n",
    "\n",
    "# Aggiungiamo colonna per sapere se il paziente ha almeno una diagnosi\n",
    "pazienti_con_diagnosi = set(diagnostics['Patient_ID'])\n",
    "tbr_by_paziente['Has_Diagnosis'] = tbr_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# Aggiungiamo anche gli intervalli nel dataframe\n",
    "tbr_by_paziente['Interval'] = tbr_intervals\n",
    "\n",
    "# Calcoliamo il numero di pazienti CON e SENZA diagnosi per ogni intervallo\n",
    "conta_per_interval = tbr_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0)\n",
    "conta_per_interval = conta_per_interval.sort_index()\n",
    "\n",
    "\n",
    "# Istogramma con due barre affiancate per ogni intervallo, con etichette\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index = range(len(conta_per_interval))\n",
    "\n",
    "bar1 = plt.bar([i - bar_width/2 for i in index], conta_per_interval[False], width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2 = plt.bar([i + bar_width/2 for i in index], conta_per_interval[True], width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "# Aggiunta delle etichette numeriche sopra ogni barra\n",
    "for bars in [bar1, bar2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "\n",
    "plt.xticks(index, [str(i) for i in conta_per_interval.index], rotation=45)\n",
    "plt.xlabel('%TBR')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "tbr_values = tbr_by_paziente['%TBR']\n",
    "\n",
    "# Statistiche descrittive\n",
    "media = tbr_values.mean()\n",
    "mediana = tbr_values.median()\n",
    "asimmetria = skew(tbr_values) #skewness\n",
    "curtosi = kurtosis(tbr_values)\n",
    "\n",
    "tar_arrotondato = tbr_values.round()\n",
    "moda = tar_arrotondato.mode()\n",
    "\n",
    "# Outlier con metodo IQR (Interquartile Range)\n",
    "# calcola Q1, Q3 e IQR\n",
    "q1 = tbr_values.quantile(0.25)\n",
    "q3 = tbr_values.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# soglie per outlier\n",
    "lower_thr = q1 - 1.5 * iqr\n",
    "upper_thr = q3 + 1.5 * iqr\n",
    "\n",
    "print(f\"Q1 = {q1:.2f}%, Q3 = {q3:.2f}%, IQR = {iqr:.2f}%\")\n",
    "print(f\"Soglia inferiore = {lower_thr:.2f}%, soglia superiore = {upper_thr:.2f}%\")\n",
    "outliers = tbr_values[(tbr_values < lower_thr) | (tbr_values > upper_thr)]\n",
    "print(\"Valori TBR considerati outlier:\")\n",
    "print(outliers.sort_values().to_list())\n",
    "\n",
    "\n",
    "\n",
    "# Output\n",
    "print(f\"Media: {media:.2f}\")\n",
    "print(f\"Mediana: {mediana:.2f}\")\n",
    "print(f\"Asimmetria (skewness): {asimmetria:.2f}\")\n",
    "print(f\"Curtosi (kurtosis): {curtosi:.2f}\")\n",
    "print(f\"Numero di outlier: {len(outliers)}\")\n",
    "print(\"Moda:\", moda.tolist())\n",
    "\n",
    "# Estrai le due serie\n",
    "g0 = tbr_by_paziente.loc[ tbr_by_paziente['Has_Diagnosis']==False, '%TBR']\n",
    "g1 = tbr_by_paziente.loc[ tbr_by_paziente['Has_Diagnosis']==True,  '%TBR']\n",
    "\n",
    "# Esegui il test two-sided\n",
    "u_stat, p_value = mannwhitneyu(g0, g1, alternative='two-sided')\n",
    "\n",
    "# STATISTICHE PER GRUPPO\n",
    "for nome_gruppo, gruppo in zip([\"Senza Complicanze\", \"Con Complicanze\"], [g0, g1]):\n",
    "    media   = gruppo.mean()\n",
    "    mediana = gruppo.median()\n",
    "    q1      = gruppo.quantile(0.25)\n",
    "    q3      = gruppo.quantile(0.75)\n",
    "    iqr     = q3 - q1\n",
    "\n",
    "    print(f\"\\nStatistiche per il gruppo '{nome_gruppo}':\")\n",
    "    print(f\" - Media:   {media:.2f}\")\n",
    "    print(f\" - Mediana: {mediana:.2f}\")\n",
    "    print(f\" - IQR:     {iqr:.2f} (Q3: {q3:.2f}, Q1: {q1:.2f})\")\n",
    "\n",
    "print(f\"U-statistic = {u_stat:.2f}\")\n",
    "print(f\"p-value      = {p_value:.4f}\")\n",
    "############################################################################################"
   ],
   "id": "578e522184ee7a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "parte1 = pd.read_csv(\"Excel/Parte1.csv\")\n",
    "df = pd.read_csv(\"Excel/Glucose_measurements.csv\")\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "\n",
    "# ANALISI TBR LV1\n",
    "############################################################################################\n",
    "# Funzione per calcolare il TBRLV1 di un paziente\n",
    "def calculate_tbr(misurazioni): # Prende in ingresso l'insieme di misurazioni di un singolo paziente\n",
    "    totale = len(misurazioni)   # Calcola il numero totale di misurazioni del paziente\n",
    "    righe_valide = misurazioni[(misurazioni['Measurement'] >= 54) & (misurazioni['Measurement'] < 70)] # Seleziona solo le righe che nel campo Measurement hanno un valore compreso tra 54 e 70 mg/dL\n",
    "    tbr = len(righe_valide)/totale * 100 # Calcola il %TBRLV1 facendo Misurazioni Valide/Misurazioni Totali\n",
    "    return tbr\n",
    "\n",
    "pazienti = df.groupby('Patient_ID') # Dividiamo il dataset per paziente, ogni gruppo contiene le misurazioni di un singolo paziente\n",
    "tbr_by_paziente = pazienti.apply(calculate_tbr, include_groups=False ).reset_index(name='%TBRLV1') # Calcoliamo il TBRLV1 di ogni paziente e creiamo un nuovo dataset con 2 colonne: Ptient_ID e %TBRLV1\n",
    "# tbr_by_paziente = tbr_by_paziente.sort_values(by='%TBRLV1', ascending=False)\n",
    "\n",
    "print(tbr_by_paziente)\n",
    "\n",
    "# Grafico per la percentuale di ogni paziente\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(tbr_by_paziente['Patient_ID'], tbr_by_paziente['%TBRLV1'], color='#ffa07a')\n",
    "plt.xticks([])\n",
    "plt.ylabel('% Time Below Range (54 - 70 mg/dL)')\n",
    "plt.xlabel('Pazienti')\n",
    "plt.title('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche descrittive di %TBRLV1\n",
    "print(tbr_by_paziente['%TBRLV1'].describe())\n",
    "\n",
    "bins = [0, 1] + list(range(10, 110, 10))\n",
    "tbr_intervals = pd.cut(tbr_by_paziente['%TBRLV1'], bins=bins, right=False)\n",
    "#Notazione [0,10) 0 é incluso ma 10 no\n",
    "\n",
    "# Aggiungiamo colonna per sapere se il paziente ha almeno una diagnosi\n",
    "pazienti_con_diagnosi = set(diagnostics['Patient_ID'])\n",
    "tbr_by_paziente['Has_Diagnosis'] = tbr_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# Aggiungiamo anche gli intervalli nel dataframe\n",
    "tbr_by_paziente['Interval'] = tbr_intervals\n",
    "\n",
    "# Calcoliamo il numero di pazienti CON e SENZA diagnosi per ogni intervallo\n",
    "conta_per_interval = tbr_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0)\n",
    "conta_per_interval = conta_per_interval.sort_index()\n",
    "\n",
    "# Istogramma con due barre affiancate per ogni intervallo, con etichette\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index = range(len(conta_per_interval))\n",
    "\n",
    "bar1 = plt.bar([i - bar_width/2 for i in index], conta_per_interval[False], width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2 = plt.bar([i + bar_width/2 for i in index], conta_per_interval[True], width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "# Aggiunta delle etichette numeriche sopra ogni barra\n",
    "for bars in [bar1, bar2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "\n",
    "plt.xticks(index, [str(i) for i in conta_per_interval.index], rotation=45)\n",
    "plt.xlabel('%TBRLV1')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tbr_values = tbr_by_paziente['%TBRLV1']\n",
    "\n",
    "# Statistiche descrittive\n",
    "media = tbr_values.mean()\n",
    "mediana = tbr_values.median()\n",
    "asimmetria = skew(tbr_values) #skewness\n",
    "curtosi = kurtosis(tbr_values)\n",
    "\n",
    "tar_arrotondato = tbr_values.round()\n",
    "moda = tar_arrotondato.mode()\n",
    "\n",
    "# Outlier con metodo IQR (Interquartile Range)\n",
    "# calcola Q1, Q3 e IQR\n",
    "q1 = tbr_values.quantile(0.25)\n",
    "q3 = tbr_values.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# soglie per outlier\n",
    "lower_thr = q1 - 1.5 * iqr\n",
    "upper_thr = q3 + 1.5 * iqr\n",
    "\n",
    "print(f\"Q1 = {q1:.2f}%, Q3 = {q3:.2f}%, IQR = {iqr:.2f}%\")\n",
    "print(f\"Soglia inferiore = {lower_thr:.2f}%, soglia superiore = {upper_thr:.2f}%\")\n",
    "outliers = tbr_values[(tbr_values < lower_thr) | (tbr_values > upper_thr)]\n",
    "print(\"Valori TBRLV1 considerati outlier:\")\n",
    "print(outliers.sort_values().to_list())\n",
    "\n",
    "\n",
    "\n",
    "# Output\n",
    "print(f\"Media: {media:.2f}\")\n",
    "print(f\"Mediana: {mediana:.2f}\")\n",
    "print(f\"Asimmetria (skewness): {asimmetria:.2f}\")\n",
    "print(f\"Curtosi (kurtosis): {curtosi:.2f}\")\n",
    "print(f\"Numero di outlier: {len(outliers)}\")\n",
    "print(\"Moda:\", moda.tolist())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# CALCOLO TBR SUI PRIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1) Converto Measurement_date in datetime\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date'])\n",
    "\n",
    "# 2) Calcolo la prima data di misurazione per ogni paziente\n",
    "first_dates = df.groupby('Patient_ID')['Measurement_date'].min().rename('FirstDate')\n",
    "df = df.join(first_dates, on='Patient_ID')\n",
    "\n",
    "# 3) Seleziono misurazioni entro 3 mesi dalla data iniziale\n",
    "df_3m = df[df['Measurement_date'] <= df['FirstDate'] + pd.DateOffset(months=3)]\n",
    "\n",
    "# 4) Calcolo il TIR sui primi 3 mesi\n",
    "pazienti_3m = df_3m.groupby('Patient_ID')\n",
    "tbr3m_by_paziente = pazienti_3m.apply(calculate_tbr, include_groups=False).reset_index(name='%TBRLV1_3m')\n",
    "\n",
    "# 5) Aggiungo il flag di diagnosi\n",
    "tbr3m_by_paziente['Has_Diagnosis'] = tbr3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# 6) Creo gli stessi intervalli usati prima su %TIR_3m\n",
    "tbr3m_by_paziente['Interval'] = pd.cut(tbr3m_by_paziente['%TBRLV1_3m'], bins=bins, right=False)\n",
    "\n",
    "# 7) Raggruppo e conto\n",
    "conta_per_interval_3m = tbr3m_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "# 8) Disegno l’istogramma a barre affiancate\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_3m = range(len(conta_per_interval_3m))\n",
    "\n",
    "bar1_3m = plt.bar([i - bar_width/2 for i in index_3m], conta_per_interval_3m[False],\n",
    "                   width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2_3m = plt.bar([i + bar_width/2 for i in index_3m], conta_per_interval_3m[True],\n",
    "                   width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "for bars in (bar1_3m, bar2_3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, h + 0.5, str(int(h)),\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(index_3m, [str(i) for i in conta_per_interval_3m.index], rotation=45)\n",
    "plt.xlabel('%TBRLV1_3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9) Statistiche descrittive per %TIR_3m (facoltativo)\n",
    "print(tbr3m_by_paziente['%TBRLV1_3m'].describe())\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# CALCOLO TBR SUGLI ULTIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1) Converto Measurement_date in datetime\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date'])\n",
    "\n",
    "# 2) Calcolo l'ultima data di misurazione per ogni paziente\n",
    "first_dates = df.groupby('Patient_ID')['Measurement_date'].max().rename('LastDate')\n",
    "df = df.join(first_dates, on='Patient_ID')\n",
    "\n",
    "# 3) Seleziono misurazioni entro 3 mesi dalla data finale\n",
    "df_3m = df[df['Measurement_date'] >= df['LastDate'] - pd.DateOffset(months=3)]\n",
    "\n",
    "# 4) Calcolo il TIR sugli ultimi 3 mesi\n",
    "pazienti_3m = df_3m.groupby('Patient_ID')\n",
    "tbr_last3m_by_paziente = pazienti_3m.apply(calculate_tbr, include_groups=False).reset_index(name='%TBRLV1_last3m')\n",
    "\n",
    "# Merge con i valori %TBRLV1_last3m calcolati\n",
    "parte1 = parte1.merge(\n",
    "    tbr_last3m_by_paziente[['Patient_ID', '%TBRLV1_last3m']],\n",
    "    on='Patient_ID',\n",
    "    how='left',\n",
    "    validate='one_to_one'  # Assicura che ogni paziente compaia una sola volta\n",
    ")\n",
    "\n",
    "# Controllo eventuali NaN\n",
    "missing = parte1['%TBRLV1_last3m'].isna().sum()\n",
    "print(f\"Attenzione: {missing} pazienti non hanno misurazioni per il calcolo del TBR livello 1 negli ultimi 3 mesi.\")\n",
    "\n",
    "# Salvataggio del dataset aggiornato\n",
    "parte1.to_csv(\"Excel/Parte1.csv\", index=False)\n",
    "print(\"✅ Salvato 'Excel/Parte1.csv' con la nuova colonna '%TBRLV1_last3m'.\")\n",
    "\n",
    "# 5) Aggiungo il flag di diagnosi\n",
    "tbr_last3m_by_paziente['Has_Diagnosis'] = tbr_last3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# 6) Creo gli stessi intervalli usati prima su %TIR_3m\n",
    "tbr_last3m_by_paziente['Interval'] = pd.cut(tbr_last3m_by_paziente['%TBRLV1_last3m'], bins=bins, right=False)\n",
    "\n",
    "# 7) Raggruppo e conto\n",
    "conta_per_interval_3m = tbr_last3m_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "# 8) Disegno l’istogramma a barre affiancate\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_3m = range(len(conta_per_interval_3m))\n",
    "\n",
    "bar1_3m = plt.bar([i - bar_width/2 for i in index_3m], conta_per_interval_3m[False],\n",
    "                   width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2_3m = plt.bar([i + bar_width/2 for i in index_3m], conta_per_interval_3m[True],\n",
    "                   width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "for bars in (bar1_3m, bar2_3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, h + 0.5, str(int(h)),\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(index_3m, [str(i) for i in conta_per_interval_3m.index], rotation=45)\n",
    "plt.xlabel('%TBRLV1_last3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9) Statistiche descrittive per %TIR_3m (facoltativo)\n",
    "print(tbr_last3m_by_paziente['%TBRLV1_last3m'].describe())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# TEST STATISTICO MANN–WHITNEY U: confronto TBR primi 3 mesi vs ultimi 3 mesi\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Estrazione delle due distribuzioni\n",
    "tbr_first3m = tbr3m_by_paziente['%TBRLV1_3m']\n",
    "tbr_last3m  = tbr_last3m_by_paziente['%TBRLV1_last3m']\n",
    "\n",
    "# Mann–Whitney U test (two-sided)\n",
    "u_stat_3m, p_value_3m = mannwhitneyu(tbr_first3m, tbr_last3m, alternative='two-sided')\n",
    "\n",
    "print(\"Confronto TBR Primi 3 Mesi vs Ultimi 3 Mesi\")\n",
    "print(f\" U-statistic = {u_stat_3m:.2f}\")\n",
    "print(f\" p-value      = {p_value_3m:.4f}\")\n",
    "\n",
    "# Eventuale interpretazione\n",
    "alpha = 0.05\n",
    "if p_value_3m < alpha:\n",
    "    print(\"→ Differenza statisticamente significativa (rifiutiamo H0 a α=0.05).\")\n",
    "else:\n",
    "    print(\"→ Nessuna differenza statisticamente significativa (non rifiutiamo H0 a α=0.05).\")\n",
    "############################################################################################"
   ],
   "id": "42d2fe348fa5262c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "df = pd.read_csv(\"Excel/Glucose_measurements.csv\")\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "parte1 = pd.read_csv(\"Excel/Parte1.csv\")\n",
    "\n",
    "# ANALISI TBR LV2\n",
    "############################################################################################\n",
    "# Funzione per calcolare il TBRLV2 di un paziente\n",
    "def calculate_tbr(misurazioni): # Prende in ingresso l'insieme di misurazioni di un singolo paziente\n",
    "    totale = len(misurazioni)   # Calcola il numero totale di misurazioni del paziente\n",
    "    righe_valide = misurazioni[(misurazioni['Measurement'] < 54)] # Seleziona solo le righe che nel campo Measurement hanno un valore minore di 54 mg/dL\n",
    "    tbr = len(righe_valide)/totale * 100 # Calcola il %TBRLV2 facendo Misurazioni Valide/Misurazioni Totali\n",
    "    return tbr\n",
    "\n",
    "pazienti = df.groupby('Patient_ID') # Dividiamo il dataset per paziente, ogni gruppo contiene le misurazioni di un singolo paziente\n",
    "tbr_by_paziente = pazienti.apply(calculate_tbr, include_groups=False).reset_index(name='%TBRLV2') # Calcoliamo il TBRLV2 di ogni paziente e creiamo un nuovo dataset con 2 colonne: Ptient_ID e %TBRLV2\n",
    "# tbr_by_paziente = tbr_by_paziente.sort_values(by='%TBRLV2', ascending=False)\n",
    "\n",
    "print(tbr_by_paziente)\n",
    "\n",
    "# Grafico per la percentuale di ogni paziente\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(tbr_by_paziente['Patient_ID'], tbr_by_paziente['%TBRLV2'], color='#e64100')\n",
    "plt.xticks([])\n",
    "plt.ylabel('% Time Below Range (< 54 mg/dL)')\n",
    "plt.xlabel('Pazienti')\n",
    "plt.title('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiche descrittive di %TBRLV2\n",
    "print(tbr_by_paziente['%TBRLV2'].describe())\n",
    "\n",
    "bins = [0, 1] + list(range(10, 110, 10))\n",
    "tbr_intervals = pd.cut(tbr_by_paziente['%TBRLV2'], bins=bins, right=False)\n",
    "#Notazione [0,10) 0 é incluso ma 10 no\n",
    "\n",
    "# Aggiungiamo colonna per sapere se il paziente ha almeno una diagnosi\n",
    "pazienti_con_diagnosi = set(diagnostics['Patient_ID'])\n",
    "tbr_by_paziente['Has_Diagnosis'] = tbr_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# Aggiungiamo anche gli intervalli nel dataframe\n",
    "tbr_by_paziente['Interval'] = tbr_intervals\n",
    "\n",
    "# Calcoliamo il numero di pazienti CON e SENZA diagnosi per ogni intervallo\n",
    "conta_per_interval = tbr_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0)\n",
    "conta_per_interval = conta_per_interval.sort_index()\n",
    "\n",
    "# Istogramma con due barre affiancate per ogni intervallo, con etichette\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index = range(len(conta_per_interval))\n",
    "\n",
    "bar1 = plt.bar([i - bar_width/2 for i in index], conta_per_interval[False], width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2 = plt.bar([i + bar_width/2 for i in index], conta_per_interval[True], width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "# Aggiunta delle etichette numeriche sopra ogni barra\n",
    "for bars in [bar1, bar2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, height + 0.5, str(int(height)), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "\n",
    "plt.xticks(index, [str(i) for i in conta_per_interval.index], rotation=45)\n",
    "plt.xlabel('%TBRLV2')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "tbr_values = tbr_by_paziente['%TBRLV2']\n",
    "\n",
    "# Statistiche descrittive\n",
    "media = tbr_values.mean()\n",
    "mediana = tbr_values.median()\n",
    "asimmetria = skew(tbr_values) #skewness\n",
    "curtosi = kurtosis(tbr_values)\n",
    "\n",
    "tar_arrotondato = tbr_values.round()\n",
    "moda = tar_arrotondato.mode()\n",
    "\n",
    "# Outlier con metodo IQR (Interquartile Range)\n",
    "# calcola Q1, Q3 e IQR\n",
    "q1 = tbr_values.quantile(0.25)\n",
    "q3 = tbr_values.quantile(0.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "# soglie per outlier\n",
    "lower_thr = q1 - 1.5 * iqr\n",
    "upper_thr = q3 + 1.5 * iqr\n",
    "\n",
    "print(f\"Q1 = {q1:.2f}%, Q3 = {q3:.2f}%, IQR = {iqr:.2f}%\")\n",
    "print(f\"Soglia inferiore = {lower_thr:.2f}%, soglia superiore = {upper_thr:.2f}%\")\n",
    "outliers = tbr_values[(tbr_values < lower_thr) | (tbr_values > upper_thr)]\n",
    "print(\"Valori TBRLV2 considerati outlier:\")\n",
    "print(outliers.sort_values().to_list())\n",
    "\n",
    "\n",
    "\n",
    "# Output\n",
    "print(f\"Media: {media:.2f}\")\n",
    "print(f\"Mediana: {mediana:.2f}\")\n",
    "print(f\"Asimmetria (skewness): {asimmetria:.2f}\")\n",
    "print(f\"Curtosi (kurtosis): {curtosi:.2f}\")\n",
    "print(f\"Numero di outlier: {len(outliers)}\")\n",
    "print(\"Moda:\", moda.tolist())\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# CALCOLO TBR SUI PRIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1) Converto Measurement_date in datetime\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date'])\n",
    "\n",
    "# 2) Calcolo la prima data di misurazione per ogni paziente\n",
    "first_dates = df.groupby('Patient_ID')['Measurement_date'].min().rename('FirstDate')\n",
    "df = df.join(first_dates, on='Patient_ID')\n",
    "\n",
    "# 3) Seleziono misurazioni entro 3 mesi dalla data iniziale\n",
    "df_3m = df[df['Measurement_date'] <= df['FirstDate'] + pd.DateOffset(months=3)]\n",
    "\n",
    "# 4) Calcolo il TIR sui primi 3 mesi\n",
    "pazienti_3m = df_3m.groupby('Patient_ID')\n",
    "tbr3m_by_paziente = pazienti_3m.apply(calculate_tbr, include_groups=False).reset_index(name='%TBRLV2_3m')\n",
    "\n",
    "# 5) Aggiungo il flag di diagnosi\n",
    "tbr3m_by_paziente['Has_Diagnosis'] = tbr3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# 6) Creo gli stessi intervalli usati prima su %TIR_3m\n",
    "tbr3m_by_paziente['Interval'] = pd.cut(tbr3m_by_paziente['%TBRLV2_3m'], bins=bins, right=False)\n",
    "\n",
    "# 7) Raggruppo e conto\n",
    "conta_per_interval_3m = tbr3m_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "# 8) Disegno l’istogramma a barre affiancate\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_3m = range(len(conta_per_interval_3m))\n",
    "\n",
    "bar1_3m = plt.bar([i - bar_width/2 for i in index_3m], conta_per_interval_3m[False],\n",
    "                   width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2_3m = plt.bar([i + bar_width/2 for i in index_3m], conta_per_interval_3m[True],\n",
    "                   width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "for bars in (bar1_3m, bar2_3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, h + 0.5, str(int(h)),\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(index_3m, [str(i) for i in conta_per_interval_3m.index], rotation=45)\n",
    "plt.xlabel('%TBRLV2_3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9) Statistiche descrittive per %TIR_3m (facoltativo)\n",
    "print(tbr3m_by_paziente['%TBRLV2_3m'].describe())\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# CALCOLO TBR SUGLI ULTIMI 3 MESI\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1) Converto Measurement_date in datetime\n",
    "df['Measurement_date'] = pd.to_datetime(df['Measurement_date'])\n",
    "\n",
    "# 2) Calcolo l'ultima data di misurazione per ogni paziente\n",
    "first_dates = df.groupby('Patient_ID')['Measurement_date'].max().rename('LastDate')\n",
    "df = df.join(first_dates, on='Patient_ID')\n",
    "\n",
    "# 3) Seleziono misurazioni entro 3 mesi dalla data finale\n",
    "df_3m = df[df['Measurement_date'] >= df['LastDate'] - pd.DateOffset(months=3)]\n",
    "\n",
    "# 4) Calcolo il TIR sugli ultimi 3 mesi\n",
    "pazienti_3m = df_3m.groupby('Patient_ID')\n",
    "tbr_last3m_by_paziente = pazienti_3m.apply(calculate_tbr, include_groups=False).reset_index(name='%TBRLV2_last3m')\n",
    "\n",
    "# Merge con i valori %TBRLV2_last3m calcolati\n",
    "parte1 = parte1.merge(\n",
    "    tbr_last3m_by_paziente[['Patient_ID', '%TBRLV2_last3m']],\n",
    "    on='Patient_ID',\n",
    "    how='left',\n",
    "    validate='one_to_one'\n",
    ")\n",
    "\n",
    "# Controllo eventuali pazienti senza misurazioni sufficienti\n",
    "missing = parte1['%TBRLV2_last3m'].isna().sum()\n",
    "print(f\"ℹ️  {missing} pazienti non hanno misurazioni sufficienti per il calcolo del TBR livello 2 negli ultimi 3 mesi.\")\n",
    "\n",
    "# Salvataggio del file aggiornato\n",
    "parte1.to_csv(\"Excel/Parte1.csv\", index=False)\n",
    "print(\"✅ Salvato 'Excel/Parte1.csv' con la nuova colonna '%TBRLV2_last3m'.\")\n",
    "\n",
    "# 5) Aggiungo il flag di diagnosi\n",
    "tbr_last3m_by_paziente['Has_Diagnosis'] = tbr_last3m_by_paziente['Patient_ID'].isin(pazienti_con_diagnosi)\n",
    "\n",
    "# 6) Creo gli stessi intervalli usati prima su %TIR_3m\n",
    "tbr_last3m_by_paziente['Interval'] = pd.cut(tbr_last3m_by_paziente['%TBRLV2_last3m'], bins=bins, right=False)\n",
    "\n",
    "# 7) Raggruppo e conto\n",
    "conta_per_interval_3m = tbr_last3m_by_paziente.groupby(['Interval', 'Has_Diagnosis'], observed=False).size().unstack(fill_value=0).sort_index()\n",
    "\n",
    "# 8) Disegno l’istogramma a barre affiancate\n",
    "plt.figure(figsize=(12, 6))\n",
    "bar_width = 0.4\n",
    "index_3m = range(len(conta_per_interval_3m))\n",
    "\n",
    "bar1_3m = plt.bar([i - bar_width/2 for i in index_3m], conta_per_interval_3m[False],\n",
    "                   width=bar_width, label='Senza Complicanze', color='skyblue', edgecolor='black')\n",
    "bar2_3m = plt.bar([i + bar_width/2 for i in index_3m], conta_per_interval_3m[True],\n",
    "                   width=bar_width, label='Con Complicanze', color='lightcoral', edgecolor='black')\n",
    "\n",
    "for bars in (bar1_3m, bar2_3m):\n",
    "    for bar in bars:\n",
    "        h = bar.get_height()\n",
    "        if h > 0:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, h + 0.5, str(int(h)),\n",
    "                     ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.xticks(index_3m, [str(i) for i in conta_per_interval_3m.index], rotation=45)\n",
    "plt.xlabel('%TBRLV2_last3m')\n",
    "plt.ylabel('Numero di Pazienti')\n",
    "plt.title('')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 9) Statistiche descrittive per %TIR_3m (facoltativo)\n",
    "print(tbr_last3m_by_paziente['%TBRLV2_last3m'].describe())\n",
    "############################################################################################\n",
    "############################################################################################\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "# TEST STATISTICO MANN–WHITNEY U: confronto TBR primi 3 mesi vs ultimi 3 mesi\n",
    "# ------------------------------------------------------------------------------------------------\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Estrazione delle due distribuzioni\n",
    "tbr_first3m = tbr3m_by_paziente['%TBRLV2_3m']\n",
    "tbr_last3m  = tbr_last3m_by_paziente['%TBRLV2_last3m']\n",
    "\n",
    "# Mann–Whitney U test (two-sided)\n",
    "u_stat_3m, p_value_3m = mannwhitneyu(tbr_first3m, tbr_last3m, alternative='two-sided')\n",
    "\n",
    "print(\"Confronto TBR Primi 3 Mesi vs Ultimi 3 Mesi\")\n",
    "print(f\" U-statistic = {u_stat_3m:.2f}\")\n",
    "print(f\" p-value      = {p_value_3m:.10f}\")\n",
    "\n",
    "# Eventuale interpretazione\n",
    "alpha = 0.05\n",
    "if p_value_3m < alpha:\n",
    "    print(\"→ Differenza statisticamente significativa (rifiutiamo H0 a α=0.05).\")\n",
    "else:\n",
    "    print(\"→ Nessuna differenza statisticamente significativa (non rifiutiamo H0 a α=0.05).\")"
   ],
   "id": "50b89933ff6eeaa6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#CREAZIONE DATASET CON DATA E VALORE DEI PARAMETRI BIOCHIMICI E NUMERO DI MISURAZIONI DEL GLUCOSIO CON RELATIVO VALORE MEDIO FATTO IN UN INTORNO DI 3 GIORNI DA QUELLA DATA\n",
    "############################################################################################\n",
    "# Carica e prepara i dati\n",
    "df_glucose = pd.read_csv(\"Excel/Glucose_measurements.csv\", parse_dates=[\"Measurement_date\"])\n",
    "df_bio = pd.read_csv(\"Excel/Biochemical_parameters.csv\", parse_dates=[\"Reception_date\"])\n",
    "\n",
    "records = []\n",
    "\n",
    "# Ottieni i pazienti presenti in entrambi i dataset\n",
    "common_patients = set(df_bio['Patient_ID']).intersection(set(df_glucose['Patient_ID']))\n",
    "\n",
    "# Loop per paziente\n",
    "for pid in tqdm(common_patients): #per ogni paziente in comune, mostrando la barra di avanzamento\n",
    "    glucose_p = df_glucose[df_glucose['Patient_ID'] == pid].copy() #prendi tutte le righe di glucosio e di parametri biochimici per quel paziente\n",
    "    bio_p = df_bio[df_bio['Patient_ID'] == pid].copy()\n",
    "\n",
    "    # Ordina le misurazioni di glucosio cronologicamente\n",
    "    glucose_p.sort_values(\"Measurement_date\", inplace=True)\n",
    "\n",
    "    #per ogni parametro biochimico del paziente estrae la data ed il valore\n",
    "    for _, bio_row in bio_p.iterrows():\n",
    "        reception_date = bio_row[\"Reception_date\"]\n",
    "        param_name = bio_row[\"Name\"]\n",
    "        param_value = bio_row[\"Value\"]\n",
    "\n",
    "        # Trova misurazioni di glucosio entro ±3 giorni\n",
    "        # Costruisce una mask che é TRUE per tutte le righe in glucose_p la cui data é compresa entro 3 giorni da reception_date di bio_p\n",
    "        mask = (\n",
    "                (glucose_p[\"Measurement_date\"] >= reception_date - timedelta(days=3)) &\n",
    "                (glucose_p[\"Measurement_date\"] <= reception_date + timedelta(days=3))\n",
    "        )\n",
    "        #crea un sotto-dataset contenente solo le letture di glucosio che rispettano la mashera, cioe l'intervallo di 3 giorni\n",
    "        nearby = glucose_p[mask]\n",
    "\n",
    "        #se il dataframe creato non é vuoto si aggiungono anche gli altri parametri e si fa l'append di questo a records definito prima\n",
    "        if not nearby.empty:\n",
    "            records.append({\n",
    "                \"Patient_ID\": pid,\n",
    "                \"Parameter\": param_name,\n",
    "                \"Parameter_Value\": param_value,\n",
    "                \"Reception_Date\": reception_date,\n",
    "                \"Avg_Glucose\": nearby[\"Measurement\"].mean(),\n",
    "                \"Num_Glucose_Readings\": len(nearby)\n",
    "            })\n",
    "\n",
    "# 1) Trasforma records in DataFrame\n",
    "df_results = pd.DataFrame(records)\n",
    "\n",
    "# 2) Salvalo in CSV nella cartella Excel\n",
    "output_path = \"Excel/glucose_bio_correlated.csv\"\n",
    "df_results.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(df_results)} rows to {output_path}\")\n",
    "############################################################################################"
   ],
   "id": "3884c19bd86b6a2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#SCATTERPLOT - RELAZIONE TRA VALORI DI GLUCOSIO E VALORI DELLE ANALISI FATTE\n",
    "############################################################################################\n",
    "df2 = pd.read_csv(\"Excel/glucose_bio_correlated.csv\", parse_dates=[\"Reception_Date\"])\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "\n",
    "max_param_value = df2[\"Parameter_Value\"].max()  #Valore massimo\n",
    "row_max_param = df2.loc[df2[\"Parameter_Value\"].idxmax()] #Indice di riga del valore massimo, .loc estrae l'intera riga\n",
    "\n",
    "max_avg_glucose = df2[\"Avg_Glucose\"].max()\n",
    "row_max_gluc = df2.loc[df2[\"Avg_Glucose\"].idxmax()]\n",
    "\n",
    "#Stampa dei valori massimi e relativi indici di riga\n",
    "print(f\"Massimo Parameter_Value: {max_param_value}\")\n",
    "print(\"Record corrispondente:\")\n",
    "print(row_max_param)\n",
    "print(f\"\\nMassimo Avg_Glucose: {max_avg_glucose}\")\n",
    "print(\"Record corrispondente:\")\n",
    "print(row_max_gluc)\n",
    "\n",
    "# trasforma la colonna Patient_ID di diagnostics in un insieme e crea una nuova colonna di booleani\n",
    "# se il paziente preso in considerazione si trova nel dataset diagnostics allora la nuova colonna Has_Diagnosis diventa True, altrimenti False\n",
    "diagnosed_patients = set(diagnostics[\"Patient_ID\"])\n",
    "df2[\"Has_Diagnosis\"] = df2[\"Patient_ID\"].isin(diagnosed_patients)\n",
    "\n",
    "#Preparazione diagrammi, n indica il numero di diagrammi da stampare (17), e poi vengono messe righe e colonne\n",
    "params = df2[\"Parameter\"].unique()\n",
    "n = len(params)\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "#Calcoliamo minimi e massimi dei valori che dobbiamo rappresentare sugli scatterplot, in modo che nelle 3 rappresentazioni differenti\n",
    "#l'asse delle scisse e quella delle ordinate abbia sempre gli stessi valori\n",
    "limits = {}\n",
    "for param in params:\n",
    "    sub = df2[df2[\"Parameter\"] == param]\n",
    "    x_min, x_max = sub[\"Parameter_Value\"].min(), sub[\"Parameter_Value\"].max()\n",
    "    y_min, y_max = sub[\"Avg_Glucose\"].min(), sub[\"Avg_Glucose\"].max()\n",
    "    x_pad = (x_max - x_min) * 0.05\n",
    "    y_pad = (y_max - y_min) * 0.05\n",
    "    limits[param] = {\n",
    "        \"xlim\": (x_min - x_pad, x_max + x_pad),\n",
    "        \"ylim\": (y_min - y_pad, y_max + y_pad)\n",
    "    }\n",
    "\n",
    "#Funzione di plot per gruppi, con limiti fissi\n",
    "def plot_group(df_subset, title, blue=True, red=True):\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols*4, rows*3))\n",
    "    axes = axes.flatten()\n",
    "    for ax, param in zip(axes, params):\n",
    "        sub = df_subset[df_subset[\"Parameter\"] == param]\n",
    "        if blue:\n",
    "            ax.scatter(\n",
    "                sub[~sub[\"Has_Diagnosis\"]][\"Parameter_Value\"], #Seleziona solo le righe di sub con pazienti senza complicanze\n",
    "                sub[~sub[\"Has_Diagnosis\"]][\"Avg_Glucose\"],\n",
    "                facecolors='none', edgecolors='blue', marker='o',\n",
    "                linewidths=1, label='No Complicanze'\n",
    "            )\n",
    "        if red:\n",
    "            ax.scatter(\n",
    "                sub[sub[\"Has_Diagnosis\"]][\"Parameter_Value\"], #Seleziona solo le righe di sub con pazienti con complicanze\n",
    "                sub[sub[\"Has_Diagnosis\"]][\"Avg_Glucose\"],\n",
    "                facecolors='none', edgecolors='red', marker='o',\n",
    "                linewidths=1, label='Con Complicanze'\n",
    "            )\n",
    "        # Applica limiti calcolati\n",
    "        ax.set_xlim(limits[param][\"xlim\"])\n",
    "        ax.set_ylim(limits[param][\"ylim\"])\n",
    "        ax.set_title(param, fontsize=8)\n",
    "        ax.set_xlabel(\"Param value\", fontsize=6)\n",
    "        ax.set_ylabel(\"Avg Glucose\", fontsize=6)\n",
    "        ax.legend(fontsize=6)\n",
    "    # Nascondi assi in eccesso\n",
    "    for ax in axes[n:]:\n",
    "        ax.set_visible(False)\n",
    "    fig.suptitle(title, fontsize=12, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "#Figura 1: combinato blu+rosso\n",
    "plot_group(df2, \"Tutti i pazienti: Con e Senza complicanze\", blue=True, red=True)\n",
    "\n",
    "#Figura 2: solo CON diagnosi (rosso)\n",
    "plot_group(df2, \"Solo pazienti CON complicanze\", blue=False, red=True)\n",
    "\n",
    "#Figura 3: solo SENZA diagnosi (blu)\n",
    "plot_group(df2, \"Solo pazienti SENZA complicanze\", blue=True, red=False)\n",
    "\n",
    "plt.show()\n",
    "############################################################################################"
   ],
   "id": "b2148a782fd09653"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "#BOXPLOT - RELAZIONE TRA VALORI DELLE ANALISI FATTE E COMPLICANZE - COMPLESSIVO\n",
    "############################################################################################\n",
    "\n",
    "df2 = pd.read_csv(\"Excel/glucose_bio_correlated.csv\", parse_dates=[\"Reception_Date\"])\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "\n",
    "\n",
    "df2[\"Has_Diagnosis\"] = df2[\"Patient_ID\"].isin(diagnostics[\"Patient_ID\"])\n",
    "\n",
    "# Parametri in ordine alfabetico\n",
    "params = sorted(df2[\"Parameter\"].unique())\n",
    "n = len(params)\n",
    "\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, param in enumerate(params):\n",
    "    sub = df2[df2[\"Parameter\"] == param]\n",
    "    no_diag = sub[~sub[\"Has_Diagnosis\"]][\"Parameter_Value\"]\n",
    "    yes_diag = sub[sub[\"Has_Diagnosis\"]][\"Parameter_Value\"]\n",
    "    data_to_plot = [no_diag, yes_diag]\n",
    "\n",
    "    # conteggi\n",
    "    counts = [len(no_diag), len(yes_diag)]\n",
    "    tick_labels = [f\"Senza\\n({counts[0]})\", f\"Con\\n({counts[1]})\"]\n",
    "\n",
    "    # qui uso labels= e non l'argomento posizionale\n",
    "    bp = axes[i].boxplot(\n",
    "        data_to_plot,\n",
    "        tick_labels=tick_labels,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor='lightblue'),\n",
    "        medianprops=dict(color='red')\n",
    "    )\n",
    "    axes[i].set_title(param, fontsize=9)\n",
    "    axes[i].set_ylabel(\"Valore parametro\", fontsize=8)\n",
    "    axes[i].tick_params(axis='x', labelsize=8)\n",
    "\n",
    "# Nasconde eventuali assi vuoti\n",
    "for ax in axes[n:]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Boxplot per ciascun parametro biochimico (Con vs Senza complicanze)\",\n",
    "    fontsize=14, y=1.02\n",
    ")\n",
    "fig.subplots_adjust(hspace=0.6, top=0.92)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#BOX PLOT SESSO\n",
    "########################################\n",
    "# 1) Leggi il file con le informazioni di sesso\n",
    "patient_info = pd.read_csv(\"Excel/Patient_info.csv\")  # contiene Patient_ID e Sex (M/F)\n",
    "\n",
    "# 2) Fai il merge con df2\n",
    "df2 = df2.merge(patient_info[['Patient_ID', 'Sex']], on='Patient_ID', how='left')\n",
    "\n",
    "# 3) Mappa M/F in etichette italiane\n",
    "df2['Sex_label'] = df2['Sex'].map({'M': 'Maschio', 'F': 'Femmina'})\n",
    "\n",
    "# 4) Prepara parametri e dimensioni della griglia\n",
    "params = sorted(df2[\"Parameter\"].unique())  # ← ordinamento alfabetico\n",
    "n = len(params)\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "# 5) Definisci l'ordine dei gruppi e le etichette\n",
    "group_combinations = [\n",
    "    (\"Maschio\", False),\n",
    "    (\"Maschio\", True),\n",
    "    (\"Femmina\", False),\n",
    "    (\"Femmina\", True),\n",
    "]\n",
    "\n",
    "# 6) Crea la figura e gli assi\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 7) Per ciascun parametro, disegna il boxplot con 4 gruppi\n",
    "for i, param in enumerate(params):\n",
    "    sub = df2[df2[\"Parameter\"] == param]\n",
    "    # prepara i dati e i conteggi\n",
    "    data_to_plot = []\n",
    "    counts = []\n",
    "    for sex, diag in group_combinations:\n",
    "        vals = sub[(sub[\"Sex_label\"] == sex) & (sub[\"Has_Diagnosis\"] == diag)][\"Parameter_Value\"]\n",
    "        data_to_plot.append(vals)\n",
    "        counts.append(len(vals))\n",
    "    # etichette con conteggio\n",
    "    tick_labels = [\n",
    "        f\"M-Senza\\n({counts[0]})\",\n",
    "        f\"M-Con\\n({counts[1]})\",\n",
    "        f\"F-Senza\\n({counts[2]})\",\n",
    "        f\"F-Con\\n({counts[3]})\",\n",
    "    ]\n",
    "\n",
    "    axes[i].boxplot(\n",
    "        data_to_plot,\n",
    "        tick_labels=tick_labels,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor='lightblue'),\n",
    "        medianprops=dict(color='red')\n",
    "    )\n",
    "    axes[i].set_title(param, fontsize=9)\n",
    "    axes[i].set_ylabel(\"Valore parametro\", fontsize=8)\n",
    "    # Ruota le etichette se servono\n",
    "    axes[i].tick_params(axis='x', rotation=45, labelsize=7)\n",
    "\n",
    "# 8) Nascondi eventuali assi vuoti\n",
    "for ax in axes[n:]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "# 9) Titolo e spacing verticale\n",
    "fig.suptitle(\n",
    "    \"Boxplot per ciascun parametro biochimico\\nMaschi vs Femmine, Senza vs Con complicanze\",\n",
    "    fontsize=14, y=1.02\n",
    ")\n",
    "fig.subplots_adjust(hspace=0.8, top=0.92)\n",
    "\n",
    "# 10) Mostra\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#BOX PLOT ETA\n",
    "########################################\n",
    "# --- 1) Calcola l'età al 2025 basandoti sul Birth_year ---\n",
    "current_year = 2025\n",
    "patient_info['Age'] = current_year - patient_info['Birth_year']\n",
    "\n",
    "# --- 2) Definisci le fasce d'età ---\n",
    "bins = [0, 30, 50, 70, 120]\n",
    "labels = ['<30', '30–49', '50–69', '≥70']\n",
    "patient_info['Age_group'] = pd.cut(\n",
    "    patient_info['Age'],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# --- 3) Associa le fasce d'età a df2 (merge se non già fatto) ---\n",
    "df2 = df2.merge(\n",
    "    patient_info[['Patient_ID', 'Age_group']],\n",
    "    on='Patient_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- 4) Prepara parametri e dimensioni della griglia ---\n",
    "params = sorted(df2[\"Parameter\"].unique())  # ← ordinamento alfabetico\n",
    "n = len(params)\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "# --- 5) Prepara le combinazioni Age × Diagnosi e le relative etichette ---\n",
    "group_combinations = [\n",
    "    (age, diag)\n",
    "    for age in labels\n",
    "    for diag in [False, True]\n",
    "]\n",
    "\n",
    "# 6) Crea la figura e gli assi\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# --- 7) Disegna il boxplot per ciascun parametro e ciascuna combinazione ---\n",
    "for i, param in enumerate(params):\n",
    "    sub = df2[df2[\"Parameter\"] == param]\n",
    "    # prepara i dati e i conteggi\n",
    "    data_to_plot = []\n",
    "    counts = []\n",
    "    for age_group, diag in group_combinations:\n",
    "        vals = sub[\n",
    "            (sub[\"Age_group\"] == age_group) &\n",
    "            (sub[\"Has_Diagnosis\"] == diag)\n",
    "        ][\"Parameter_Value\"]\n",
    "        data_to_plot.append(vals)\n",
    "        counts.append(len(vals))\n",
    "\n",
    "    # etichette con conteggio\n",
    "    tick_labels = [\n",
    "        f\"{age_group}-{'Con' if diag else 'Senza'}\\n({cnt})\"\n",
    "        for (age_group, diag), cnt in zip(group_combinations, counts)\n",
    "    ]\n",
    "\n",
    "    axes[i].boxplot(\n",
    "        data_to_plot,\n",
    "        tick_labels=tick_labels,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor='lightblue'),\n",
    "        medianprops=dict(color='red')\n",
    "    )\n",
    "    axes[i].set_title(param, fontsize=10)\n",
    "    axes[i].set_ylabel(\"Valore parametro\", fontsize=9)\n",
    "    axes[i].tick_params(axis='x', rotation=45, labelsize=7)\n",
    "\n",
    "# --- 8) Nascondi eventuali assi vuoti ---\n",
    "for ax in axes[n:]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "# --- 9) Titolo e layout ---\n",
    "fig.suptitle(\n",
    "    \"Boxplot per ciascun parametro biochimico\\n\"\n",
    "    \"suddivisi per fasce d'età e complicanze\",\n",
    "    fontsize=16, y=1.02\n",
    ")\n",
    "fig.subplots_adjust(hspace=0.8, top=0.92)\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- 10) Mostra la figura ---\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def compute_stats(df, group_cols):\n",
    "    \"\"\"\n",
    "    Restituisce un DataFrame con, per ogni gruppo:\n",
    "      - count\n",
    "      - mean\n",
    "      - std\n",
    "      - median\n",
    "      - q25 (25° percentile)\n",
    "      - q75 (75° percentile)\n",
    "      - IQR (q75 - q25)\n",
    "    \"\"\"\n",
    "    # Raggruppa e calcola tutte le statistiche in un colpo solo\n",
    "    agg = df.groupby(group_cols, observed=True)[\"Parameter_Value\"].agg(\n",
    "        count   = \"count\",\n",
    "        mean    = \"mean\",\n",
    "        std     = \"std\",\n",
    "        median  = \"median\",\n",
    "        q25     = lambda x: x.quantile(0.25),\n",
    "        q75     = lambda x: x.quantile(0.75),\n",
    "    )\n",
    "\n",
    "    # Calcola l'IQR\n",
    "    agg[\"IQR\"] = agg[\"q75\"] - agg[\"q25\"]\n",
    "\n",
    "    # Porta indici di gruppo in colonne\n",
    "    return agg.reset_index()\n",
    "\n",
    "# 1) Statistiche per COMPLESSIVO, Parameter × Has_Diagnosis\n",
    "stats_overall_diag = compute_stats(df2, [\"Parameter\", \"Has_Diagnosis\"])\n",
    "print(stats_overall_diag.to_string(index=False))\n",
    "\n",
    "# 2) COMPLESSIVO, Parameter × Sex_label × Has_Diagnosis\n",
    "stats_overall_sex  = compute_stats(df2, [\"Parameter\", \"Sex_label\", \"Has_Diagnosis\"])\n",
    "print(stats_overall_sex.to_string(index=False))\n",
    "\n",
    "# 3) COMPLESSIVO, Parameter × Age_group × Has_Diagnosis\n",
    "stats_overall_age  = compute_stats(df2, [\"Parameter\", \"Age_group\", \"Has_Diagnosis\"])\n",
    "print(stats_overall_age.to_string(index=False))\n",
    "\n",
    "# 4) Sotto‐insieme “ultimi 3 mesi”\n",
    "cutoff     = pd.Timestamp.today() - pd.Timedelta(days=90)\n",
    "df_recent  = df2[df2[\"Reception_Date\"] >= cutoff]\n",
    "\n",
    "# 5) Stesse statistiche su RECENTI\n",
    "stats_recent_diag = compute_stats(df_recent, [\"Parameter\", \"Has_Diagnosis\"])\n",
    "stats_recent_sex  = compute_stats(df_recent, [\"Parameter\", \"Sex_label\", \"Has_Diagnosis\"])\n",
    "stats_recent_age  = compute_stats(df_recent, [\"Parameter\", \"Age_group\", \"Has_Diagnosis\"])\n",
    "\n",
    "# 6) Delta percentuali (esempio per mediana)\n",
    "merge = stats_overall_diag.merge(\n",
    "    stats_recent_diag,\n",
    "    on=[\"Parameter\", \"Has_Diagnosis\"],\n",
    "    suffixes=(\"_all\", \"_3m\")\n",
    ")\n",
    "merge[\"delta_mediana_%\"] = 100 * (merge[\"median_3m\"] - merge[\"median_all\"]) / merge[\"median_all\"]\n",
    "print(merge[[\"Parameter\", \"Has_Diagnosis\", \"delta_mediana_%\"]])\n",
    "\n",
    "\n",
    "############################################################################################"
   ],
   "id": "256b04442ffda0a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "#BOXPLOT - RELAZIONE TRA VALORI DELLE ANALISI FATTE E COMPLICANZE - ULTIMI 3 MESI\n",
    "############################################################################################\n",
    "\n",
    "df2 = pd.read_csv(\"Excel/glucose_bio_correlated.csv\", parse_dates=[\"Reception_Date\"])\n",
    "diagnostics = pd.read_csv(\"Excel/Diagnostics.csv\")\n",
    "\n",
    "# --- FILTRO: ultimi 3 mesi dall'ultima analisi per ciascun paziente ---\n",
    "last_dates = df2.groupby('Patient_ID')['Reception_Date'].transform('max')\n",
    "threshold = last_dates - pd.DateOffset(months=3)\n",
    "df2 = df2[df2['Reception_Date'] >= threshold]\n",
    "\n",
    "df2[\"Has_Diagnosis\"] = df2[\"Patient_ID\"].isin(diagnostics[\"Patient_ID\"])\n",
    "\n",
    "# Parametri in ordine alfabetico\n",
    "params = sorted(df2[\"Parameter\"].unique())\n",
    "n = len(params)\n",
    "\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, param in enumerate(params):\n",
    "    sub = df2[df2[\"Parameter\"] == param]\n",
    "    no_diag = sub[~sub[\"Has_Diagnosis\"]][\"Parameter_Value\"]\n",
    "    yes_diag = sub[sub[\"Has_Diagnosis\"]][\"Parameter_Value\"]\n",
    "    data_to_plot = [no_diag, yes_diag]\n",
    "\n",
    "    # conteggi\n",
    "    counts = [len(no_diag), len(yes_diag)]\n",
    "    tick_labels = [f\"Senza\\n({counts[0]})\", f\"Con\\n({counts[1]})\"]\n",
    "\n",
    "    # qui uso labels= e non l'argomento posizionale\n",
    "    bp = axes[i].boxplot(\n",
    "        data_to_plot,\n",
    "        tick_labels=tick_labels,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor='lightblue'),\n",
    "        medianprops=dict(color='red')\n",
    "    )\n",
    "    axes[i].set_title(param, fontsize=9)\n",
    "    axes[i].set_ylabel(\"Valore parametro\", fontsize=8)\n",
    "    axes[i].tick_params(axis='x', labelsize=8)\n",
    "\n",
    "# Nasconde eventuali assi vuoti\n",
    "for ax in axes[n:]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "fig.suptitle(\n",
    "    \"Boxplot per ciascun parametro biochimico (Con vs Senza complicanze)\",\n",
    "    fontsize=14, y=1.02\n",
    ")\n",
    "fig.subplots_adjust(hspace=0.6, top=0.92)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#BOX PLOT SESSO\n",
    "########################################\n",
    "# 1) Leggi il file con le informazioni di sesso\n",
    "patient_info = pd.read_csv(\"Excel/Patient_info.csv\")  # contiene Patient_ID e Sex (M/F)\n",
    "\n",
    "# 2) Fai il merge con df2\n",
    "df2 = df2.merge(patient_info[['Patient_ID', 'Sex']], on='Patient_ID', how='left')\n",
    "\n",
    "# 3) Mappa M/F in etichette italiane\n",
    "df2['Sex_label'] = df2['Sex'].map({'M': 'Maschio', 'F': 'Femmina'})\n",
    "\n",
    "# 4) Prepara parametri e dimensioni della griglia\n",
    "params = sorted(df2[\"Parameter\"].unique())  # ← ordinamento alfabetico\n",
    "n = len(params)\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "# 5) Definisci l'ordine dei gruppi e le etichette\n",
    "group_combinations = [\n",
    "    (\"Maschio\", False),\n",
    "    (\"Maschio\", True),\n",
    "    (\"Femmina\", False),\n",
    "    (\"Femmina\", True),\n",
    "]\n",
    "\n",
    "# 6) Crea la figura e gli assi\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# 7) Per ciascun parametro, disegna il boxplot con 4 gruppi\n",
    "for i, param in enumerate(params):\n",
    "    sub = df2[df2[\"Parameter\"] == param]\n",
    "    # prepara i dati e i conteggi\n",
    "    data_to_plot = []\n",
    "    counts = []\n",
    "    for sex, diag in group_combinations:\n",
    "        vals = sub[(sub[\"Sex_label\"] == sex) & (sub[\"Has_Diagnosis\"] == diag)][\"Parameter_Value\"]\n",
    "        data_to_plot.append(vals)\n",
    "        counts.append(len(vals))\n",
    "    # etichette con conteggio\n",
    "    tick_labels = [\n",
    "        f\"M-Senza\\n({counts[0]})\",\n",
    "        f\"M-Con\\n({counts[1]})\",\n",
    "        f\"F-Senza\\n({counts[2]})\",\n",
    "        f\"F-Con\\n({counts[3]})\",\n",
    "    ]\n",
    "\n",
    "    axes[i].boxplot(\n",
    "        data_to_plot,\n",
    "        tick_labels=tick_labels,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor='lightblue'),\n",
    "        medianprops=dict(color='red')\n",
    "    )\n",
    "    axes[i].set_title(param, fontsize=9)\n",
    "    axes[i].set_ylabel(\"Valore parametro\", fontsize=8)\n",
    "    # Ruota le etichette se servono\n",
    "    axes[i].tick_params(axis='x', rotation=45, labelsize=7)\n",
    "\n",
    "# 8) Nascondi eventuali assi vuoti\n",
    "for ax in axes[n:]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "# 9) Titolo e spacing verticale\n",
    "fig.suptitle(\n",
    "    \"Boxplot per ciascun parametro biochimico\\nMaschi vs Femmine, Senza vs Con complicanze\",\n",
    "    fontsize=14, y=1.02\n",
    ")\n",
    "fig.subplots_adjust(hspace=0.8, top=0.92)\n",
    "\n",
    "# 10) Mostra\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#BOX PLOT ETA\n",
    "########################################\n",
    "# --- 1) Calcola l'età al 2025 basandoti sul Birth_year ---\n",
    "current_year = 2025\n",
    "patient_info['Age'] = current_year - patient_info['Birth_year']\n",
    "\n",
    "# --- 2) Definisci le fasce d'età ---\n",
    "bins = [0, 30, 50, 70, 120]\n",
    "labels = ['<30', '30–49', '50–69', '≥70']\n",
    "patient_info['Age_group'] = pd.cut(\n",
    "    patient_info['Age'],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# --- 3) Associa le fasce d'età a df2 (merge se non già fatto) ---\n",
    "df2 = df2.merge(\n",
    "    patient_info[['Patient_ID', 'Age_group']],\n",
    "    on='Patient_ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# --- 4) Prepara parametri e dimensioni della griglia ---\n",
    "params = sorted(df2[\"Parameter\"].unique())  # ← ordinamento alfabetico\n",
    "n = len(params)\n",
    "cols = 4\n",
    "rows = (n + cols - 1) // cols\n",
    "\n",
    "# --- 5) Prepara le combinazioni Age × Diagnosi e le relative etichette ---\n",
    "group_combinations = [\n",
    "    (age, diag)\n",
    "    for age in labels\n",
    "    for diag in [False, True]\n",
    "]\n",
    "\n",
    "# 6) Crea la figura e gli assi\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# --- 7) Disegna il boxplot per ciascun parametro e ciascuna combinazione ---\n",
    "for i, param in enumerate(params):\n",
    "    sub = df2[df2[\"Parameter\"] == param]\n",
    "    # prepara i dati e i conteggi\n",
    "    data_to_plot = []\n",
    "    counts = []\n",
    "    for age_group, diag in group_combinations:\n",
    "        vals = sub[\n",
    "            (sub[\"Age_group\"] == age_group) &\n",
    "            (sub[\"Has_Diagnosis\"] == diag)\n",
    "        ][\"Parameter_Value\"]\n",
    "        data_to_plot.append(vals)\n",
    "        counts.append(len(vals))\n",
    "\n",
    "    # etichette con conteggio\n",
    "    tick_labels = [\n",
    "        f\"{age_group}-{'Con' if diag else 'Senza'}\\n({cnt})\"\n",
    "        for (age_group, diag), cnt in zip(group_combinations, counts)\n",
    "    ]\n",
    "\n",
    "    axes[i].boxplot(\n",
    "        data_to_plot,\n",
    "        tick_labels=tick_labels,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(facecolor='lightblue'),\n",
    "        medianprops=dict(color='red')\n",
    "    )\n",
    "    axes[i].set_title(param, fontsize=10)\n",
    "    axes[i].set_ylabel(\"Valore parametro\", fontsize=9)\n",
    "    axes[i].tick_params(axis='x', rotation=45, labelsize=7)\n",
    "\n",
    "# --- 8) Nascondi eventuali assi vuoti ---\n",
    "for ax in axes[n:]:\n",
    "    ax.set_visible(False)\n",
    "\n",
    "# --- 9) Titolo e layout ---\n",
    "fig.suptitle(\n",
    "    \"Boxplot per ciascun parametro biochimico\\n\"\n",
    "    \"suddivisi per fasce d'età e complicanze\",\n",
    "    fontsize=16, y=1.02\n",
    ")\n",
    "fig.subplots_adjust(hspace=0.8, top=0.92)\n",
    "plt.tight_layout()\n",
    "\n",
    "# --- 10) Mostra la figura ---\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def compute_stats(df, group_cols):\n",
    "    \"\"\"\n",
    "    Restituisce un DataFrame con, per ogni gruppo:\n",
    "      - count\n",
    "      - mean\n",
    "      - std\n",
    "      - median\n",
    "      - q25 (25° percentile)\n",
    "      - q75 (75° percentile)\n",
    "      - IQR (q75 - q25)\n",
    "    \"\"\"\n",
    "    # Raggruppa e calcola tutte le statistiche in un colpo solo\n",
    "    agg = df.groupby(group_cols, observed=True)[\"Parameter_Value\"].agg(\n",
    "        count   = \"count\",\n",
    "        mean    = \"mean\",\n",
    "        std     = \"std\",\n",
    "        median  = \"median\",\n",
    "        q25     = lambda x: x.quantile(0.25),\n",
    "        q75     = lambda x: x.quantile(0.75),\n",
    "    )\n",
    "\n",
    "    # Calcola l'IQR\n",
    "    agg[\"IQR\"] = agg[\"q75\"] - agg[\"q25\"]\n",
    "\n",
    "    # Porta indici di gruppo in colonne\n",
    "    return agg.reset_index()\n",
    "\n",
    "# 1) Statistiche per COMPLESSIVO, Parameter × Has_Diagnosis\n",
    "stats_overall_diag = compute_stats(df2, [\"Parameter\", \"Has_Diagnosis\"])\n",
    "print(stats_overall_diag.to_string(index=False))\n",
    "\n",
    "# 2) COMPLESSIVO, Parameter × Sex_label × Has_Diagnosis\n",
    "stats_overall_sex  = compute_stats(df2, [\"Parameter\", \"Sex_label\", \"Has_Diagnosis\"])\n",
    "print(stats_overall_sex.to_string(index=False))\n",
    "\n",
    "# 3) COMPLESSIVO, Parameter × Age_group × Has_Diagnosis\n",
    "stats_overall_age  = compute_stats(df2, [\"Parameter\", \"Age_group\", \"Has_Diagnosis\"])\n",
    "print(stats_overall_age.to_string(index=False))\n",
    "\n",
    "# 4) Sotto‐insieme “ultimi 3 mesi”\n",
    "cutoff     = pd.Timestamp.today() - pd.Timedelta(days=90)\n",
    "df_recent  = df2[df2[\"Reception_Date\"] >= cutoff]\n",
    "\n",
    "# 5) Stesse statistiche su RECENTI\n",
    "stats_recent_diag = compute_stats(df_recent, [\"Parameter\", \"Has_Diagnosis\"])\n",
    "stats_recent_sex  = compute_stats(df_recent, [\"Parameter\", \"Sex_label\", \"Has_Diagnosis\"])\n",
    "stats_recent_age  = compute_stats(df_recent, [\"Parameter\", \"Age_group\", \"Has_Diagnosis\"])\n",
    "\n",
    "# 6) Delta percentuali (esempio per mediana)\n",
    "merge = stats_overall_diag.merge(\n",
    "    stats_recent_diag,\n",
    "    on=[\"Parameter\", \"Has_Diagnosis\"],\n",
    "    suffixes=(\"_all\", \"_3m\")\n",
    ")\n",
    "merge[\"delta_mediana_%\"] = 100 * (merge[\"median_3m\"] - merge[\"median_all\"]) / merge[\"median_all\"]\n",
    "print(merge[[\"Parameter\", \"Has_Diagnosis\", \"delta_mediana_%\"]])\n",
    "############################################################################################"
   ],
   "id": "dc91ca6c413ec153"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# CREAZIONE NUOVO DASET PARTE 1\n",
    "############################################################################################\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# 1) Carica il file\n",
    "df = pd.read_csv(\"Excel/Patient_info.csv\")\n",
    "\n",
    "# 2) Seleziona le colonne di interesse\n",
    "parte1 = df[['Patient_ID', 'Sex', 'Birth_year', 'Number_of_diagnostics']].copy()\n",
    "\n",
    "# 3) Mappa Sex in binario: 1 = maschio, 0 = femmina\n",
    "#    Adatta la mappatura ai valori esatti presenti nel tuo CSV (es. 'Male'/'Female', 'M'/'F', ecc.)\n",
    "parte1['Sex'] = parte1['Sex'].map({'M': 1, 'F': 0})\n",
    "\n",
    "# 4) Trasforma Number_of_diagnostics in variabile binaria Has_Diagnostics\n",
    "parte1['Has_Diagnostics'] = (parte1['Number_of_diagnostics'] >= 1).astype(int)\n",
    "\n",
    "# 5) Calcola l'età a partire dall'anno di nascita e sostituisci Birth_year\n",
    "current_year = datetime.now().year\n",
    "parte1['Age'] = current_year - parte1['Birth_year']\n",
    "\n",
    "# 6) Rimuovi le colonne originali non più necessarie\n",
    "parte1 = parte1.drop(columns=['Birth_year', 'Number_of_diagnostics'])\n",
    "\n",
    "# 7) Riorganizza le colonne finali\n",
    "parte1 = parte1[['Patient_ID', 'Sex', 'Age', 'Has_Diagnostics']]\n",
    "\n",
    "# 8) Salva su CSV\n",
    "parte1.to_csv(\"Excel/Parte1.csv\", index=False)\n",
    "\n",
    "print(\"File salvato in Excel/Parte1.csv\")\n",
    "\n"
   ],
   "id": "5a880ec1fa8af148"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T13:30:11.232288Z",
     "start_time": "2025-05-27T13:30:11.214095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carica i due dataset\n",
    "df1 = pd.read_csv(\"Excel/Parte1.csv\")\n",
    "df2 = pd.read_csv(\"parte2_v1.csv\")\n",
    "\n",
    "# Rimuove la colonna \"Complicanze\" dal secondo dataset\n",
    "df2 = df2.drop(columns=[\"Complicanze\"])\n",
    "\n",
    "# Effettua il merge tra df1 (usando Patient_ID) e df2 (usando ID)\n",
    "merged_df = pd.merge(df1, df2, left_on=\"Patient_ID\", right_on=\"ID\", how=\"inner\")\n",
    "\n",
    "# Rimuove la colonna \"ID\" e \"Patient_ID\"\n",
    "merged_df = merged_df.drop(columns=[\"ID\",\"Patient_ID\"])\n",
    "\n",
    "# Salva il dataframe risultante in un file CSV\n",
    "merged_df.to_csv(\"Excel/Clustering.csv\", index=False)\n",
    "\n",
    "print(\"Merge completato. File salvato come 'merged_dataset.csv'.\")\n"
   ],
   "id": "8613521cd79a040c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge completato. File salvato come 'merged_dataset.csv'.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-27T16:39:55.805818Z",
     "start_time": "2025-05-27T16:39:43.405105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import confusion_matrix, silhouette_score\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"Excel/Clustering.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"Has_Diagnostics\"])\n",
    "y = df[\"Has_Diagnostics\"]\n",
    "\n",
    "# Definisci i quattro imputatori\n",
    "imputers = {\n",
    "    # Sostituisce ogni valore mancante con la media aritmetica della colonna\n",
    "    \"Mean\":    SimpleImputer(strategy=\"mean\"),\n",
    "\n",
    "    # Sostituisce ogni valore mancante con la mediana (valore centrale) della colonna,\n",
    "    \"Median\":  SimpleImputer(strategy=\"median\"),\n",
    "\n",
    "    # Per ogni riga con missing, calcola i k (=5) pazienti più “simili” sulle altre feature\n",
    "    # e sostituisce i NaN con la media dei valori corrispondenti di quei vicini\n",
    "    \"KNN\":     KNNImputer(n_neighbors=5),\n",
    "\n",
    "     # Imputa in modo iterativo (MICE):\n",
    "    # 1) Inizializza i NaN (es. con la media)\n",
    "    # 2) Per ogni colonna con missing, allena un modello sulle altre variabili per prevedere i NaN\n",
    "    # 3) Ripete la procedura a catena per max_iter volte, migliorando progressivamente le stime\n",
    "    \"MICE\":    IterativeImputer(max_iter=10, random_state=42)\n",
    "}\n",
    "\n",
    "# 4) Griglia di iperparametri per KMeans\n",
    "param_grid = {\n",
    "    'n_clusters': [2],              # fisso a 2\n",
    "    'init':       ['k-means++', 'random'],\n",
    "    'n_init':     [10, 20],\n",
    "    'max_iter':   [100, 300],\n",
    "    'tol':        [1e-4, 1e-3],\n",
    "    'algorithm':  ['lloyd', 'elkan']\n",
    "}\n",
    "\n",
    "# 5) Funzione di valutazione\n",
    "def evaluate(imputer_name, imputer, params):\n",
    "    # a) Imputa i dati mancanti con il metodo scelto\n",
    "    X_imp = imputer.fit_transform(X)\n",
    "    # b) Standardizzazione\n",
    "    X_scaled = StandardScaler().fit_transform(X_imp)\n",
    "    # c) Configura e applica KMeans\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=params['n_clusters'],\n",
    "        init=params['init'],\n",
    "        n_init=params['n_init'],\n",
    "        max_iter=params['max_iter'],\n",
    "        tol=params['tol'],\n",
    "        algorithm=params['algorithm'],\n",
    "        random_state=42\n",
    "    )\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "    # d) Metriche\n",
    "    sil = silhouette_score(X_scaled, clusters)\n",
    "    cm  = confusion_matrix(y, clusters)\n",
    "    return sil, cm\n",
    "\n",
    "# 6) Loop su imputatori e griglia\n",
    "results = []\n",
    "# essenzialmente con qeusto ciclo facciamo si che per ogni strategia di imputazione (media, mediana, KNN, MICE) vengano provate tutte le combinazioni di parametri\n",
    "for imp_name, imp in imputers.items():\n",
    "    for init in param_grid['init']:\n",
    "        for n_init in param_grid['n_init']:\n",
    "            for max_iter in param_grid['max_iter']:\n",
    "                for tol in param_grid['tol']:\n",
    "                    for algo in param_grid['algorithm']:\n",
    "                        params = {\n",
    "                            'n_clusters': 2,\n",
    "                            'init':       init,\n",
    "                            'n_init':     n_init,\n",
    "                            'max_iter':   max_iter,\n",
    "                            'tol':        tol,\n",
    "                            'algorithm':  algo\n",
    "                        }\n",
    "                        sil, cm = evaluate(imp_name, imp, params)\n",
    "                        results.append({\n",
    "                            'Imputer': imp_name,\n",
    "                            **params,\n",
    "                            'Silhouette': sil,\n",
    "                            'ConfusionMatrix': cm\n",
    "                        })\n",
    "                        print(f\"{imp_name} | init={init}, n_init={n_init}, \"\n",
    "                              f\"max_iter={max_iter}, tol={tol}, algo={algo} \"\n",
    "                              f\"-> silhouette={sil:.3f}\")\n",
    "                        print(cm)"
   ],
   "id": "eb2e4fd5f8ce22d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean | init=k-means++, n_init=10, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=10, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=10, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[ 99 126]\n",
      " [218 280]]\n",
      "Mean | init=k-means++, n_init=10, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[ 99 126]\n",
      " [218 280]]\n",
      "Mean | init=k-means++, n_init=10, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=10, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=10, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[ 99 126]\n",
      " [218 280]]\n",
      "Mean | init=k-means++, n_init=10, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[ 99 126]\n",
      " [218 280]]\n",
      "Mean | init=k-means++, n_init=20, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=20, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=20, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=20, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=20, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=20, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=20, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=k-means++, n_init=20, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.109\n",
      "[[126  99]\n",
      " [283 215]]\n",
      "Mean | init=random, n_init=10, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.109\n",
      "[[ 99 126]\n",
      " [215 283]]\n",
      "Mean | init=random, n_init=10, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.109\n",
      "[[ 99 126]\n",
      " [215 283]]\n",
      "Mean | init=random, n_init=10, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.111\n",
      "[[128  97]\n",
      " [293 205]]\n",
      "Mean | init=random, n_init=10, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.111\n",
      "[[128  97]\n",
      " [293 205]]\n",
      "Mean | init=random, n_init=10, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.109\n",
      "[[ 99 126]\n",
      " [215 283]]\n",
      "Mean | init=random, n_init=10, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.109\n",
      "[[ 99 126]\n",
      " [215 283]]\n",
      "Mean | init=random, n_init=10, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.111\n",
      "[[128  97]\n",
      " [293 205]]\n",
      "Mean | init=random, n_init=10, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.111\n",
      "[[128  97]\n",
      " [293 205]]\n",
      "Mean | init=random, n_init=20, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.109\n",
      "[[ 99 126]\n",
      " [215 283]]\n",
      "Mean | init=random, n_init=20, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.109\n",
      "[[ 99 126]\n",
      " [215 283]]\n",
      "Mean | init=random, n_init=20, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.111\n",
      "[[128  97]\n",
      " [293 205]]\n",
      "Mean | init=random, n_init=20, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.111\n",
      "[[128  97]\n",
      " [293 205]]\n",
      "Mean | init=random, n_init=20, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.109\n",
      "[[ 99 126]\n",
      " [215 283]]\n",
      "Mean | init=random, n_init=20, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.109\n",
      "[[ 99 126]\n",
      " [215 283]]\n",
      "Mean | init=random, n_init=20, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.111\n",
      "[[128  97]\n",
      " [293 205]]\n",
      "Mean | init=random, n_init=20, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.111\n",
      "[[128  97]\n",
      " [293 205]]\n",
      "Median | init=k-means++, n_init=10, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=10, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=10, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=10, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=10, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=10, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=10, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=10, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=20, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=20, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=20, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [281 217]]\n",
      "Median | init=k-means++, n_init=20, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [281 217]]\n",
      "Median | init=k-means++, n_init=20, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=20, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=k-means++, n_init=20, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [281 217]]\n",
      "Median | init=k-means++, n_init=20, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [281 217]]\n",
      "Median | init=random, n_init=10, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=10, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=10, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=10, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=10, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=10, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=10, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=10, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=20, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=20, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=20, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=20, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=20, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=20, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=20, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "Median | init=random, n_init=20, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.108\n",
      "[[126  99]\n",
      " [280 218]]\n",
      "KNN | init=k-means++, n_init=10, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=10, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=10, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=10, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=10, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=10, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=10, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=10, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=20, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=20, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=20, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=20, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=20, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=20, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=20, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=k-means++, n_init=20, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.114\n",
      "[[ 94 131]\n",
      " [210 288]]\n",
      "KNN | init=random, n_init=10, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.113\n",
      "[[129  96]\n",
      " [288 210]]\n",
      "KNN | init=random, n_init=10, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.113\n",
      "[[129  96]\n",
      " [288 210]]\n",
      "KNN | init=random, n_init=10, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.113\n",
      "[[ 96 129]\n",
      " [210 288]]\n",
      "KNN | init=random, n_init=10, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.113\n",
      "[[ 96 129]\n",
      " [210 288]]\n",
      "KNN | init=random, n_init=10, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.113\n",
      "[[129  96]\n",
      " [288 210]]\n",
      "KNN | init=random, n_init=10, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.113\n",
      "[[129  96]\n",
      " [288 210]]\n",
      "KNN | init=random, n_init=10, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.113\n",
      "[[ 96 129]\n",
      " [210 288]]\n",
      "KNN | init=random, n_init=10, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.113\n",
      "[[ 96 129]\n",
      " [210 288]]\n",
      "KNN | init=random, n_init=20, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.114\n",
      "[[ 93 132]\n",
      " [210 288]]\n",
      "KNN | init=random, n_init=20, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.114\n",
      "[[ 93 132]\n",
      " [210 288]]\n",
      "KNN | init=random, n_init=20, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.115\n",
      "[[135  90]\n",
      " [288 210]]\n",
      "KNN | init=random, n_init=20, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.115\n",
      "[[135  90]\n",
      " [288 210]]\n",
      "KNN | init=random, n_init=20, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.114\n",
      "[[ 93 132]\n",
      " [210 288]]\n",
      "KNN | init=random, n_init=20, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.114\n",
      "[[ 93 132]\n",
      " [210 288]]\n",
      "KNN | init=random, n_init=20, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.115\n",
      "[[135  90]\n",
      " [288 210]]\n",
      "KNN | init=random, n_init=20, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.115\n",
      "[[135  90]\n",
      " [288 210]]\n",
      "MICE | init=k-means++, n_init=10, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=10, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=10, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=10, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=10, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=10, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=10, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=10, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=20, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=20, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=20, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=20, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=20, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=20, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=20, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=k-means++, n_init=20, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.122\n",
      "[[143  82]\n",
      " [312 186]]\n",
      "MICE | init=random, n_init=10, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=10, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=10, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=10, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=10, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=10, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=10, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=10, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=20, max_iter=100, tol=0.0001, algo=lloyd -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=20, max_iter=100, tol=0.0001, algo=elkan -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=20, max_iter=100, tol=0.001, algo=lloyd -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=20, max_iter=100, tol=0.001, algo=elkan -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=20, max_iter=300, tol=0.0001, algo=lloyd -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=20, max_iter=300, tol=0.0001, algo=elkan -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=20, max_iter=300, tol=0.001, algo=lloyd -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n",
      "MICE | init=random, n_init=20, max_iter=300, tol=0.001, algo=elkan -> silhouette=0.120\n",
      "[[ 84 141]\n",
      " [189 309]]\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}

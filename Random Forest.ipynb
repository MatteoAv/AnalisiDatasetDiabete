{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e2e3211ada0d75b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inizializzazione variabili"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a8d365ed61cd250"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, IterativeImputer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Percorso dove salvare l'excel\n",
    "excel_path = \"Excel/Bilanciamento/RandomForest_Results_Bilanced_complicanze.xlsx\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T08:08:50.668027200Z",
     "start_time": "2025-06-24T08:08:50.661945500Z"
    }
   },
   "id": "99f98a9cbe832858",
   "execution_count": 400
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Genera il dataset\n",
    "parte1 = pd.read_csv(\"Parte1_classificato_bilanciato.csv\")\n",
    "parte2 = pd.read_csv(\"Excel/Bilanciamento/parte2_v4_bilanced.csv\")\n",
    "\n",
    "# Viene rinominata la feature ID in Patiene_ID per perettere il merge\n",
    "parte2 = parte2.rename(columns={\"ID\": \"Patient_ID\"})\n",
    "#parte2 = parte2.drop(columns=[\"Complicanze\"])\n",
    "\n",
    "\n",
    "# Viene fatto un inner‐merge su Patient_ID:\n",
    "df = parte1.merge(parte2, on=\"Patient_ID\", how=\"inner\")\n",
    "df = df.drop(columns=[\"Patient_ID\"])\n",
    "\n",
    "# Dividi X e Y\n",
    "Y = df['TipoComplicanza']\n",
    "X = df.drop(columns=['TipoComplicanza'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T17:11:34.744401Z",
     "start_time": "2025-06-24T17:11:34.720633400Z"
    }
   },
   "id": "961a27ebcaa5cf07",
   "execution_count": 671
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Funzione per metriche\n",
    "def get_metrics(y_true, y_predicted):\n",
    "    matrix = confusion_matrix(y_true, y_predicted)\n",
    "    accuracy = accuracy_score(y_true, y_predicted)\n",
    "    precision = precision_score(y_true, y_predicted, average='weighted', zero_division=0)\n",
    "    recall = recall_score(y_true, y_predicted, average='weighted', zero_division=0)\n",
    "    f1score = f1_score(y_true, y_predicted, average='weighted', zero_division=0)\n",
    "    return matrix, accuracy, precision, recall, f1score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T16:52:06.117114500Z",
     "start_time": "2025-06-23T16:52:06.071205300Z"
    }
   },
   "id": "dc528a44abdd7487",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Riempimento valori null con la media"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e69b2625af8123b5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_media = df.fillna(df.mean(numeric_only=True))\n",
    "\n",
    "# Dividi X e Y\n",
    "del X, Y\n",
    "Y = df_media['TipoComplicanza']\n",
    "X = df_media.drop(columns=['TipoComplicanza'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T17:14:21.930168800Z",
     "start_time": "2025-06-24T17:14:21.918827200Z"
    }
   },
   "id": "943341e0ee44265",
   "execution_count": 688
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Riempimento valori null con la mediana"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9ba982d8c798d5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_mediana = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Dividi X e Y\n",
    "del X, Y\n",
    "Y = df_mediana['TipoComplicanza']\n",
    "X = df_mediana.drop(columns=['TipoComplicanza'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T17:15:17.492327100Z",
     "start_time": "2025-06-24T17:15:17.480437400Z"
    }
   },
   "id": "f84a073b3b1e6f40",
   "execution_count": 705
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Riempimento valori null con KNNImputer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e42483d3e8f309c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Rimuovi momentaneamente X e Y\n",
    "df_temp = df.copy()\n",
    "\n",
    "# Crea un imputatore KNN\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Applica l'imputazione solo sulle colonne numeriche\n",
    "df_imputed_array = imputer.fit_transform(df_temp.select_dtypes(include='number'))\n",
    "\n",
    "# Ricrea il DataFrame con le stesse colonne\n",
    "df_imputed = pd.DataFrame(df_imputed_array, columns=df_temp.select_dtypes(include='number').columns)\n",
    "\n",
    "# Se ci sono colonne non numeriche, le aggiungiamo di nuovo (senza modificarle)\n",
    "for col in df_temp.columns:\n",
    "    if col not in df_imputed.columns:\n",
    "        df_imputed[col] = df_temp[col]\n",
    "\n",
    "# Dividi X e Y\n",
    "del X, Y\n",
    "Y = df_imputed['TipoComplicanza']\n",
    "X = df_imputed.drop(columns=['TipoComplicanza'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T17:17:04.606434300Z",
     "start_time": "2025-06-24T17:17:04.590055Z"
    }
   },
   "id": "6338be6e58bcceaa",
   "execution_count": 722
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Riempimento valori null con IterativeImputer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "333c5326ae40e2e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Rimuovi momentaneamente X e Y\n",
    "df_temp = df.copy()\n",
    "\n",
    "# Crea un imputatore iterativo\n",
    "imputer = IterativeImputer(max_iter=100, random_state=42)\n",
    "\n",
    "# Applica l'imputazione solo sulle colonne numeriche\n",
    "df_imputed_array = imputer.fit_transform(df_temp.select_dtypes(include='number'))\n",
    "\n",
    "# Ricrea il DataFrame con le stesse colonne\n",
    "df_imputed = pd.DataFrame(df_imputed_array, columns=df_temp.select_dtypes(include='number').columns)\n",
    "\n",
    "# Se ci sono colonne non numeriche, le aggiungiamo di nuovo (senza modificarle)\n",
    "for col in df_temp.columns:\n",
    "    if col not in df_imputed.columns:\n",
    "        df_imputed[col] = df_temp[col]\n",
    "\n",
    "# Dividi X e Y\n",
    "del X, Y\n",
    "Y = df_imputed['TipoComplicanza']\n",
    "X = df_imputed.drop(columns=['TipoComplicanza'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T17:18:19.742382300Z",
     "start_time": "2025-06-24T17:18:16.055730500Z"
    }
   },
   "id": "3c1316516dc3cdc5",
   "execution_count": 739
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Prova = 80\n",
    "n_estimators = 300\n",
    "max_depth = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T17:19:00.334157100Z",
     "start_time": "2025-06-24T17:19:00.321738900Z"
    }
   },
   "id": "123dd65ead26b47d",
   "execution_count": 752
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metodo dell 80/20"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c46d0b5a824caafa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDAZIONE 80/20 ===\n",
      "✅ Risultati 80/20 salvati su Excel.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== VALIDAZIONE 80/20 ===\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "cm, acc, prec, rec, f1 = get_metrics(y_test, y_pred)\n",
    "\n",
    "#print(f\"Accuracy: {acc:.4f}\")\n",
    "#print(f\"Precision: {prec:.4f}\")\n",
    "#print(f\"Recall: {rec:.4f}\")\n",
    "#print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "#disp.plot(cmap=plt.cm.Blues)\n",
    "#plt.title(\"Confusion Matrix 80/20\")\n",
    "#plt.show()\n",
    "\n",
    "# Calcola importanza delle feature\n",
    "importances = clf.feature_importances_\n",
    "features = X.columns\n",
    "importances_dict = {f'Imp_{feat}': [imp] for feat, imp in zip(features, importances)}\n",
    "\n",
    "# Prepara il DataFrame da salvare\n",
    "df_split = pd.DataFrame({\n",
    "    'Prova': [Prova],\n",
    "    'n_estimators': [n_estimators],\n",
    "    'max_depth': [max_depth],\n",
    "    'Accuracy': [acc],\n",
    "    'Precision': [prec],\n",
    "    'Recall': [rec],\n",
    "    'F1-Score': [f1],\n",
    "    'Confusion_Matrix': [cm.tolist()],\n",
    "    ' ': [None]\n",
    "} | importances_dict)  # Unione dizionari\n",
    "\n",
    "# Aggiungi a eventuali dati già presenti\n",
    "if os.path.exists(excel_path):\n",
    "    with pd.ExcelFile(excel_path) as reader:\n",
    "        if 'Split_80_20' in reader.sheet_names:\n",
    "            prev_data = pd.read_excel(reader, sheet_name='Split_80_20')\n",
    "            df_split = pd.concat([prev_data, df_split], ignore_index=True)\n",
    "\n",
    "# Scrivi sul file\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df_split.to_excel(writer, sheet_name='Split_80_20', index=False)\n",
    "\n",
    "print(\"✅ Risultati 80/20 salvati su Excel.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T17:19:03.230132Z",
     "start_time": "2025-06-24T17:19:00.949490500Z"
    }
   },
   "id": "8ddee73f823b18d3",
   "execution_count": 753
  },
  {
   "cell_type": "markdown",
   "source": [
    "## K-Fold cross recognition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e4bc7b7d117a911"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDAZIONE K-FOLD ===\n",
      "✅ Risultati K-Fold salvati su Excel.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== VALIDAZIONE K-FOLD ===\")\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(X, Y), start=1):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    cm, acc, prec, rec, f1 = get_metrics(y_test, y_pred)\n",
    "\n",
    "#    print(f\"\\n--- Fold {i} ---\")\n",
    "#    print(f\"Accuracy: {acc:.4f}\")\n",
    "#    print(f\"Precision: {prec:.4f}\")\n",
    "#    print(f\"Recall: {rec:.4f}\")\n",
    "#    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "#    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "#    disp.plot(cmap=plt.cm.Blues)\n",
    "#    plt.title(f\"Confusion Matrix Fold {i}\")\n",
    "#    plt.show()\n",
    "\n",
    "    # Calcola importanza delle feature\n",
    "    importances = clf.feature_importances_\n",
    "    features = X.columns\n",
    "    importances_dict = {f'Imp_{feat}': imp for feat, imp in zip(features, importances)}\n",
    "\n",
    "    # Salva tutti i dati in un'unica riga\n",
    "    fold_results.append({\n",
    "        'Prova': Prova,\n",
    "        'KFold' : i,\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Confusion_Matrix': cm.tolist(),\n",
    "        ' ': None,  # cella vuota per separare le metriche dalle importances\n",
    "        **importances_dict\n",
    "    })\n",
    "\n",
    "df_kfold = pd.DataFrame(fold_results)\n",
    "\n",
    "# Aggiungi a eventuali dati già presenti\n",
    "if os.path.exists(excel_path):\n",
    "    with pd.ExcelFile(excel_path) as reader:\n",
    "        if 'KFold_CV' in reader.sheet_names:\n",
    "            prev_kfold = pd.read_excel(reader, sheet_name='KFold_CV')\n",
    "            df_kfold = pd.concat([prev_kfold, df_kfold], ignore_index=True)\n",
    "\n",
    "# Scrivi sul file\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df_kfold.to_excel(writer, sheet_name='KFold_CV', index=False)\n",
    "\n",
    "print(\"✅ Risultati K-Fold salvati su Excel.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T17:19:08.123572200Z",
     "start_time": "2025-06-24T17:19:03.232277300Z"
    }
   },
   "id": "f2336578911cf3fc",
   "execution_count": 754
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TRAIN-FOLD / TEST-HOLDOUT validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55e30b4b94d16471"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VALIDAZIONE TRAIN-FOLD / TEST-HOLDOUT ===\n",
      "✅ Risultati nested fold salvati su Excel.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== VALIDAZIONE TRAIN-FOLD / TEST-HOLDOUT ===\")\n",
    "val_results = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=42)\n",
    "\n",
    "for i, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), start=1):\n",
    "    X_fold_train = X_train.iloc[train_idx]\n",
    "    y_fold_train = y_train.iloc[train_idx]\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    clf.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "    # Si testa sempre sullo stesso 20%\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    cm, acc, prec, rec, f1 = get_metrics(y_test, y_pred)\n",
    "\n",
    "#    print(f\"\\n--- Fold {i} (train su fold, test fisso) ---\")\n",
    "#    print(f\"Accuracy: {acc:.4f}\")\n",
    "#    print(f\"Precision: {prec:.4f}\")\n",
    "#    print(f\"Recall: {rec:.4f}\")\n",
    "#    print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "#    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "#    disp.plot(cmap=plt.cm.Blues)\n",
    "#    plt.title(f\"Confusion Matrix Fold {i}\")\n",
    "#    plt.show()\n",
    "\n",
    "    # Feature importances\n",
    "    importances = clf.feature_importances_\n",
    "    importances_dict = {f'Imp_{feat}': imp for feat, imp in zip(X.columns, importances)}\n",
    "\n",
    "    # Salva i risultati del fold\n",
    "    val_results.append({\n",
    "        'Prova': Prova,\n",
    "        'KFold' : i,\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1,\n",
    "        'Confusion_Matrix': cm.tolist(),\n",
    "        ' ': None,  # cella vuota per separare le metriche dalle importances\n",
    "        **importances_dict\n",
    "    })\n",
    "\n",
    "# Crea il DataFrame\n",
    "df_nested = pd.DataFrame(val_results)\n",
    "\n",
    "# Se esiste già, aggiungi i dati al foglio\n",
    "if os.path.exists(excel_path):\n",
    "    with pd.ExcelFile(excel_path) as reader:\n",
    "        if 'TrainFold_TestFixed' in reader.sheet_names:\n",
    "            prev_nested = pd.read_excel(reader, sheet_name='TrainFold_TestFixed')\n",
    "            df_nested = pd.concat([prev_nested, df_nested], ignore_index=True)\n",
    "            \n",
    "# Salva su Excel\n",
    "with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    df_nested.to_excel(writer, sheet_name='TrainFold_TestFixed', index=False)\n",
    "\n",
    "print(\"✅ Risultati nested fold salvati su Excel.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T17:19:12.597036400Z",
     "start_time": "2025-06-24T17:19:08.124584600Z"
    }
   },
   "id": "58aa474531f64e1e",
   "execution_count": 755
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-23T17:07:38.127170100Z",
     "start_time": "2025-06-23T17:07:38.113026800Z"
    }
   },
   "id": "10ffc66724337f4d",
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
